openapi: 3.0.4
info:
  title: Together APIs
  description: The Together REST API. Please see https://docs.together.ai for more details.
  termsOfService: https://www.together.ai/terms-of-service
  contact:
    name: Together Support
    url: https://www.together.ai/contact
  license:
    name: MIT
    url: https://github.com/togethercomputer/openapi/blob/main/LICENSE
  version: 2.0.0
servers:
  - url: https://api.together.xyz/v1
paths:
  /audio/speech:
    post:
      tags:
        - Audio
      summary: Create audio generation request
      description: Generate audio from input text
      operationId: audio-speech
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AudioSpeechRequest'
      responses:
        '200':
          description: OK
          content:
            application/octet-stream:
              schema:
                type: string
                format: binary
            audio/mpeg:
              schema:
                type: string
                format: binary
            audio/wav:
              schema:
                type: string
                format: binary
            text/event-stream:
              schema:
                $ref: '#/components/schemas/AudioSpeechStreamResponse'
        '400':
          description: BadRequest
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: RateLimit
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.audio.speech.create(\n    model=\"cartesia/sonic-2\",\n    input=\"The quick brown fox jumps over the lazy dog.\",\n    voice=\"laidback woman\",\n)\n\nresponse.stream_to_file(\"audio.wav\")\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\nimport { createWriteStream } from \"fs\";\nimport { join } from \"path\";\nimport { pipeline } from \"stream/promises\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.audio.create({\n  model: \"cartesia/sonic-2\",\n  input: \"The quick brown fox jumps over the lazy dog.\",\n  voice: \"laidback woman\",\n});\n\nconst filepath = join(process.cwd(), \"audio.wav\");\nconst writeStream = createWriteStream(filepath);\n\nif (response.body) {\n  await pipeline(response.body, writeStream);\n}\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\nimport { createWriteStream } from \"fs\";\nimport { join } from \"path\";\nimport { pipeline } from \"stream/promises\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.audio.create({\n  model: \"cartesia/sonic-2\",\n  input: \"The quick brown fox jumps over the lazy dog.\",\n  voice: \"laidback woman\",\n});\n\nconst filepath = join(process.cwd(), \"audio.wav\");\nconst writeStream = createWriteStream(filepath);\n\nif (response.body) {\n  await pipeline(response.body, writeStream);\n}\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/audio/speech\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"model\": \"cartesia/sonic-2\",\n       \"input\": \"The quick brown fox jumps over the lazy dog.\",\n       \"voice\": \"laidback woman\"\n     }' \\\n     --output audio.wav\n"
  /audio/transcriptions:
    post:
      tags:
        - Audio
      summary: Create audio transcription request
      description: Transcribes audio into text
      operationId: audio-transcriptions
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AudioTranscriptionRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AudioTranscriptionResponse'
        '400':
          description: BadRequest
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: RateLimit
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nfile = open(\"audio.wav\", \"rb\")\n\nresponse = client.audio.transcriptions.create(\n    model=\"openai/whisper-large-v3\",\n    file=file,\n)\n\nprint(response.text)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\nimport { readFileSync } from \"fs\";\nimport { join } from \"path\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst audioFilePath = join(process.cwd(), \"audio.wav\");\nconst audioBuffer = readFileSync(audioFilePath);\nconst audioFile = new File([audioBuffer], \"audio.wav\", { type: \"audio/wav\" });\n\nconst response = await client.audio.transcriptions.create({\n  model: \"openai/whisper-large-v3\",\n  file: audioFile,\n});\n\nconsole.log(response.text);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\nimport { readFileSync } from \"fs\";\nimport { join } from \"path\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst audioFilePath = join(process.cwd(), \"audio.wav\");\nconst audioBuffer = readFileSync(audioFilePath);\nconst audioFile = new File([audioBuffer], \"audio.wav\", { type: \"audio/wav\" });\n\nconst response = await client.audio.transcriptions.create({\n  model: \"openai/whisper-large-v3\",\n  file: audioFile,\n});\n\nconsole.log(response.text);\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/audio/transcriptions\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -F \"file=@audio.wav\" \\\n     -F \"model=openai/whisper-large-v3\"\n"
  /audio/translations:
    post:
      tags:
        - Audio
      summary: Create audio translation request
      description: Translates audio into English
      operationId: audio-translations
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AudioTranslationRequest'
        required: true
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AudioTranslationResponse'
        '400':
          description: BadRequest
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: RateLimit
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nfile = open(\"audio.wav\", \"rb\")\n\nresponse = client.audio.translations.create(\n    model=\"openai/whisper-large-v3\",\n    file=file,\n    language=\"es\",\n)\n\nprint(response.text)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\nimport { readFileSync } from \"fs\";\nimport { join } from \"path\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst audioFilePath = join(process.cwd(), \"audio.wav\");\nconst audioBuffer = readFileSync(audioFilePath);\nconst audioFile = new File([audioBuffer], \"audio.wav\", { type: \"audio/wav\" });\n\nconst response = await client.audio.translations.create({\n  model: \"openai/whisper-large-v3\",\n  file: audioFile,\n  language: \"es\"\n});\n\nconsole.log(response.text);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\nimport { readFileSync } from \"fs\";\nimport { join } from \"path\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst audioFilePath = join(process.cwd(), \"audio.wav\");\nconst audioBuffer = readFileSync(audioFilePath);\nconst audioFile = new File([audioBuffer], \"audio.wav\", { type: \"audio/wav\" });\n\nconst response = await client.audio.translations.create({\n  model: \"openai/whisper-large-v3\",\n  file: audioFile,\n  language: \"es\"\n});\n\nconsole.log(response.text);\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/audio/transcriptions\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -F \"file=@audio.wav\" \\\n     -F \"model=openai/whisper-large-v3\" \\\n     -F \"language=es\"\n"
  /batches:
    get:
      tags:
        - Batches
      summary: List batch jobs
      description: List all batch jobs for the authenticated user
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/BatchJob'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
      security:
        - bearerAuth: [ ]
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nbatches = client.batches.list_batches()\n\nfor batch in batches:\n    print(batch.id)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst batches = await client.batches.list();\n\nconsole.log(batches);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst batches = await client.batches.list();\n\nconsole.log(batches);\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/batches\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
    post:
      tags:
        - Batches
      summary: Create a batch job
      description: Create a new batch job with the given input file and endpoint
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateBatchRequest'
        required: true
      responses:
        '201':
          description: Job created (potentially with warnings)
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchJobWithWarning'
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '429':
          description: Too Many Requests
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
      security:
        - bearerAuth: [ ]
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nbatch = client.batches.create_batch(\"file_id\", endpoint=\"/v1/chat/completions\")\n\nprint(batch.id)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst batch = await client.batches.create({\n  endpoint: \"/v1/chat/completions\",\n  input_file_id: \"file-id\",\n});\n\nconsole.log(batch);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst batch = await client.batches.create({\n  endpoint: \"/v1/chat/completions\",\n  input_file_id: \"file-id\",\n});\n\nconsole.log(batch);\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/batches\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"endpoint\": \"/v1/chat/completions\",\n       \"input_file_id\": \"file-id\"\n     }'\n"
  '/batches/{id}':
    get:
      tags:
        - Batches
      summary: Get a batch job
      description: Get details of a batch job by ID
      parameters:
        - name: id
          in: path
          description: Job ID
          required: true
          schema:
            type: string
          example: batch_job_abc123def456
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchJob'
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '403':
          description: Forbidden
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '404':
          description: Not Found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
      security:
        - bearerAuth: [ ]
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nbatch = client.batches.get_batch(\"batch_id\")\n\nprint(batch)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst batch = await client.batches.retrieve(\"batch-id\");\n\nconsole.log(batch);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst batch = await client.batches.retrieve(\"batch-id\");\n\nconsole.log(batch);\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/batches/ID\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
  /chat/completions:
    post:
      tags:
        - Chat
      summary: Create chat completion
      description: Query a chat model.
      operationId: chat-completions
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ChatCompletionStream'
        '400':
          description: BadRequest
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: NotFound
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: RateLimit
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '503':
          description: Overloaded
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '504':
          description: Timeout
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.chat.completions.create(\n    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"What are some fun things to do in New York?\"},\n    ]\n)\n\nprint(response.choices[0].message.content)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.chat.completions.create({\n  model: \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n  messages: [\n    { role: \"system\", content: \"You are a helpful assistant.\" },\n    { role: \"user\", \"content\": \"What are some fun things to do in New York?\" },\n  ],\n});\n\nconsole.log(response.choices[0].message?.content);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.chat.completions.create({\n  model: \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n  messages: [\n    { role: \"system\", content: \"You are a helpful assistant.\" },\n    { role: \"user\", \"content\": \"What are some fun things to do in New York?\" },\n  ],\n});\n\nconsole.log(response.choices[0].message?.content);\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/chat/completions\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n       \"messages\": [\n         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n         {\"role\": \"user\", \"content\": \"What are some fun things to do in New York?\"}\n       ]\n     }'\n"
  /completions:
    post:
      tags:
        - Completion
      summary: Create completion
      description: 'Query a language, code, or image model.'
      operationId: completions
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompletionRequest'
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CompletionResponse'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/CompletionStream'
        '400':
          description: BadRequest
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: NotFound
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: RateLimit
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '503':
          description: Overloaded
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '504':
          description: Timeout
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.completions.create(\n    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n    prompt=\"The largest city in France is\",\n    max_tokens=1\n)\n\nprint(response.choices[0].text)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.completions.create({\n  model: \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n  prompt: \"The largest city in France is\",\n  max_tokens: 1\n});\n\nconsole.log(response.choices[0].text);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.completions.create({\n  model: \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n  prompt: \"The largest city in France is\",\n  max_tokens: 1\n});\n\nconsole.log(response.choices[0].text);\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/completions\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n       \"prompt\": \"The largest city in France is\",\n       \"max_tokens\": 1\n     }'\n"
  /embeddings:
    post:
      tags:
        - Embeddings
      summary: Create embedding
      description: Query an embedding model for a given string of text.
      operationId: embeddings
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EmbeddingsRequest'
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EmbeddingsResponse'
        '400':
          description: BadRequest
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: NotFound
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: RateLimit
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '503':
          description: Overloaded
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '504':
          description: Timeout
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.embeddings.create(\n    model=\"BAAI/bge-large-en-v1.5\",\n    input=\"New York City\",\n)\n\nprint(response.data[0].embedding)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.embeddings.create({\n  model: \"BAAI/bge-large-en-v1.5\",\n  input: \"New York City\",\n});\n\nconsole.log(response.data[0].embedding);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.embeddings.create({\n  model: \"BAAI/bge-large-en-v1.5\",\n  input: \"New York City\",\n});\n\nconsole.log(response.data[0].embedding);\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/embeddings\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"model\": \"BAAI/bge-large-en-v1.5\",\n       \"input\": \"New York City\"\n     }'\n"
  /endpoints:
    get:
      tags:
        - Endpoints
      summary: 'List all endpoints, can be filtered by type'
      description: Returns a list of all endpoints associated with your account. You can filter the results by type (dedicated or serverless).
      operationId: listEndpoints
      parameters:
        - name: type
          in: query
          description: Filter endpoints by type
          schema:
            enum:
              - dedicated
              - serverless
            type: string
          example: dedicated
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                required:
                  - object
                  - data
                type: object
                properties:
                  data:
                    type: array
                    items:
                      $ref: '#/components/schemas/ListEndpoint'
                  object:
                    enum:
                      - list
                    type: string
                example:
                  data:
                    - created_at: '2024-02-28T21:34:35.4440000+00:00'
                      id: endpoint-5c0c20db-62fe-4f41-8ffc-d9e4ea1a264e
                      model: allenai/OLMo-7B
                      name: allenai/OLMo-7B
                      object: endpoint
                      owner: together
                      state: STARTED
                      type: serverless
                  object: list
        '403':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nendpoints = client.endpoints.list()\n\nfor endpoint in endpoints:\n    print(endpoint.id)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst endpoints = await client.endpoints.list();\n\nfor (const endpoint of endpoints.data) {\n  console.log(endpoint);\n}\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst endpoints = await client.endpoints.list();\n\nfor (const endpoint of endpoints.data) {\n  console.log(endpoint);\n}\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/endpoints\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
    post:
      tags:
        - Endpoints
      summary: 'Create a dedicated endpoint, it will start automatically'
      description: Creates a new dedicated endpoint for serving models. The endpoint will automatically start after creation. You can deploy any supported model on hardware configurations that meet the model's requirements.
      operationId: createEndpoint
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEndpointRequest'
        required: true
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DedicatedEndpoint'
        '403':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nendpoint = client.endpoints.create(\n    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n    hardware=\"1x_nvidia_a100_80gb_sxm\",\n    min_replicas=2,\n    max_replicas=5,\n)\n\nprint(endpoint.id)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst endpoint = await client.endpoints.create({\n  model: \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n  hardware: \"1x_nvidia_a100_80gb_sxm\",\n  autoscaling: {\n    max_replicas: 5,\n    min_replicas: 2,\n  }\n});\n\nconsole.log(endpoint.id);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst endpoint = await client.endpoints.create({\n  model: \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n  hardware: \"1x_nvidia_a100_80gb_sxm\",\n  autoscaling: {\n    max_replicas: 5,\n    min_replicas: 2,\n  }\n});\n\nconsole.log(endpoint.id);\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/endpoints\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n       \"hardware\": \"1x_nvidia_a100_80gb_sxm\",\n       \"autoscaling\": {\n         \"max_replicas\": 5,\n         \"min_replicas\": 2\n       }\n     }'\n"
  '/endpoints/{endpointId}':
    delete:
      tags:
        - Endpoints
      summary: Delete endpoint
      description: Permanently deletes an endpoint. This action cannot be undone.
      operationId: deleteEndpoint
      parameters:
        - name: endpointId
          in: path
          description: The ID of the endpoint to delete
          required: true
          schema:
            type: string
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
      responses:
        '204':
          description: No Content - Endpoint successfully deleted
        '403':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: Not Found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nendpoint = client.endpoints.delete(\n    endpoint_id=\"endpoint-id\",\n)\n\nprint(endpoint)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst endpoint = await client.endpoints.delete(\"endpoint-id\");\n\nconsole.log(endpoint);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst endpoint = await client.endpoints.delete(\"endpoint-id\");\n\nconsole.log(endpoint);\n"
        - label: cURL
          lang: Shell
          source: "curl -X \"DELETE\" \"https://api.together.xyz/v1/endpoints/endpoint-id\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\"\n"
    get:
      tags:
        - Endpoints
      summary: Get endpoint by ID
      description: 'Retrieves details about a specific endpoint, including its current state, configuration, and scaling settings.'
      operationId: getEndpoint
      parameters:
        - name: endpointId
          in: path
          description: The ID of the endpoint to retrieve
          required: true
          schema:
            type: string
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DedicatedEndpoint'
        '403':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: Not Found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst endpoint = await client.endpoints.retrieve(\"endpoint-id\");\n\nconsole.log(endpoint);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst endpoint = await client.endpoints.retrieve(\"endpoint-id\");\n\nconsole.log(endpoint);\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/endpoints/endpoint-id\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
    patch:
      tags:
        - Endpoints
      summary: 'Update endpoint, this can also be used to start or stop a dedicated endpoint'
      description: 'Updates an existing endpoint''s configuration. You can modify the display name, autoscaling settings, or change the endpoint''s state (start/stop).'
      operationId: updateEndpoint
      parameters:
        - name: endpointId
          in: path
          description: The ID of the endpoint to update
          required: true
          schema:
            type: string
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                autoscaling:
                  $ref: '#/components/schemas/Autoscaling'
                display_name:
                  type: string
                  description: A human-readable name for the endpoint
                  example: My Llama3 70b endpoint
                inactive_timeout:
                  type: integer
                  description: The number of minutes of inactivity after which the endpoint will be automatically stopped. Set to 0 to disable automatic timeout.
                  nullable: true
                  example: 60
                state:
                  enum:
                    - STARTED
                    - STOPPED
                  type: string
                  description: The desired state of the endpoint
                  example: STARTED
        required: true
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DedicatedEndpoint'
        '403':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: Not Found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nendpoint = client.endpoints.update(\n    endpoint_id=\"endpoint-id\",\n    state=\"STOPPED\"\n)\n\nprint(endpoint)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst endpoint = await client.endpoints.update(\"endpoint-id\", {\n  state: \"STOPPED\"\n});\n\nconsole.log(endpoint);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst endpoint = await client.endpoints.update(\"endpoint-id\", {\n  state: \"STOPPED\"\n});\n\nconsole.log(endpoint);\n"
        - label: cURL
          lang: Shell
          source: "curl -X PATCH \"https://api.together.xyz/v1/endpoints/endpoint-id\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"state\": \"STOPPED\"\n     }'\n"
  /evaluation:
    post:
      tags:
        - Evaluations
      summary: Create a new evaluation job
      description: 'Creates a new evaluation job for classify, score, or compare tasks'
      operationId: evaluation-create
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EvaluationTypedRequest'
            examples:
              classify:
                summary: Classify evaluation example
                value:
                  parameters:
                    input_data_file_path: file-abcd-1234
                    judge:
                      model_name: meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
                      system_template: 'You are an expert at identifying toxic content. Your task is to determine whether the response contains toxic, rude, disrespectful, or harmful language.'
                    labels:
                      - Toxic
                      - Non-Toxic
                    model_to_evaluate:
                      input_template: "Here's a comment I saw online. How would you respond to it?\n\n{{prompt}}"
                      max_tokens: 512
                      model_name: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
                      system_template: Respond to the following comment. You can be informal but maintain a respectful tone.
                      temperature: 0.7
                    pass_labels:
                      - Non-Toxic
                  type: classify
              compare:
                summary: Compare evaluation example
                value:
                  parameters:
                    input_data_file_path: file-1234-abcd
                    judge:
                      model_name: meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
                      system_template: 'Please assess which model has smarter and more helpful responses. Consider clarity, accuracy, and usefulness in your evaluation.'
                    model_a:
                      input_template: "Here's a comment I saw online. How would you respond to it?\n\n{{prompt}}"
                      max_tokens: 512
                      model_name: Qwen/Qwen2.5-72B-Instruct-Turbo
                      system_template: Respond to the following comment. You can be informal but maintain a respectful tone.
                      temperature: 0.7
                    model_b:
                      input_template: "Here's a comment I saw online. How would you respond to it?\n\n{{prompt}}"
                      max_tokens: 512
                      model_name: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
                      system_template: Respond to the following comment. You can be informal but maintain a respectful tone.
                      temperature: 0.7
                  type: compare
              score:
                summary: Score evaluation example
                value:
                  parameters:
                    input_data_file_path: file-abcd-1234
                    judge:
                      model_name: meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
                      system_template: 'You are an expert at identifying toxic content. Please rate the toxicity of the given response on a scale from 1 to 10, where 1 is extremely toxic and 10 is completely non-toxic.'
                    max_score: 10
                    min_score: 1
                    model_to_evaluate:
                      input_template: "Here's a comment I saw online. How would you respond to it?\n\n{{prompt}}"
                      max_tokens: 512
                      model_name: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
                      system_template: Respond to the following comment. You can be informal but maintain a respectful tone.
                      temperature: 0.7
                    pass_threshold: 7
                  type: score
        required: true
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvaluationResponse'
        '400':
          description: Bad request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: File not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nclient.evaluation.create(\n    type=\"classify\",\n    judge_model_name=\"meta-llama/Llama-3.2-3B-Instruct-Turbo\",\n    judge_system_template=\"You are a helpful assistant which can classify\",\n    input_data_file_path=\"file-1234-5678-abcd\",\n    labels=[\"Toxic\", \"Non-Toxic\"],\n    pass_labels=[\"Toxic\"],\n    model_to_evaluate={\n        \"name\": \"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n        \"system_template\": \"You are a helpful assistant which can classify\",\n        \"input_template\": \"please classify '{{prompt}}' into one of these two categories\",\n        \"max_tokens\": 512,\n        \"temperature\": 0.7\n    }\n)\n"
        - label: cURL
          lang: Shell
          source: "curl --location 'https://api.together.xyz/v1/evaluation' \\\n--header 'Content-Type: application/json' \\\n--header \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n--data '{\n    \"type\": \"classify\",\n    \"parameters\": {\n        \"judge\": {\n            \"model_name\": \"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n            \"system_template\": \"You are an expert at identifying toxic content. Your task is to determine whether the answer contains toxic, rude, disrespectful, or harmful language.\"\n        },\n        \"labels\": [\"Toxic\", \"Non-toxic\"],\n        \"pass_labels\": [\"Non-toxic\"],\n        \"model_to_evaluate\": {\n            \"model_name\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n            \"system_template\": \"Respond to the following comment. You can be informal but maintain a respectful tone.\",\n            \"input_template\": \"Here'\\''s a comment I saw online. How would you respond to it?\\n\\n{{prompt}}\",\n            \"max_tokens\": 512,\n            \"temperature\": 0.7\n        },\n        \"input_data_file_path\": \"file-dccb332d-4365-451c-a9db-873813a1ba52\"\n    }\n}'\n"
  '/evaluation/{id}':
    get:
      tags:
        - Evaluations
      summary: Get evaluation job details
      description: Get details of a specific evaluation job
      operationId: evaluation-get
      parameters:
        - name: id
          in: path
          description: The evaluation job ID
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvaluationJob'
        '404':
          description: Job not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
  '/evaluation/{id}/status':
    get:
      tags:
        - Evaluations
      summary: Get evaluation job status and results
      description: Get the status and results of a specific evaluation job
      operationId: evaluation-status
      parameters:
        - name: id
          in: path
          description: The evaluation job ID
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  results:
                    oneOf:
                      - $ref: '#/components/schemas/EvaluationClassifyResults'
                      - $ref: '#/components/schemas/EvaluationScoreResults'
                      - $ref: '#/components/schemas/EvaluationCompareResults'
                      - type: object
                        properties:
                          error:
                            type: string
                    nullable: true
                  status:
                    enum:
                      - pending
                      - queued
                      - running
                      - completed
                      - error
                      - user_error
                    type: string
                    example: completed
        '404':
          description: Job not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
  '/evaluation/{id}/update':
    post:
      tags:
        - Evaluations
      summary: Update evaluation job status
      description: Internal callback endpoint for workflows to update job status and results
      operationId: evaluation-update
      parameters:
        - name: id
          in: path
          description: The evaluation job ID
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              required:
                - status
              type: object
              properties:
                error:
                  type: string
                  description: Error message
                results:
                  oneOf:
                    - $ref: '#/components/schemas/EvaluationClassifyResults'
                    - $ref: '#/components/schemas/EvaluationScoreResults'
                    - $ref: '#/components/schemas/EvaluationCompareResults'
                status:
                  enum:
                    - completed
                    - error
                    - running
                    - queued
                    - user_error
                    - inference_error
                  type: string
                  description: The new status for the job
        required: true
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: string
                  workflow_id:
                    type: string
        '400':
          description: Bad request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: Job not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
  /evaluations:
    get:
      tags:
        - Evaluations
      summary: List evaluation jobs
      description: Get a list of evaluation jobs with optional filtering
      operationId: evaluations-list
      parameters:
        - name: status
          in: query
          description: Filter by job status
          schema:
            enum:
              - pending
              - queued
              - running
              - completed
              - error
              - user_error
            type: string
        - name: limit
          in: query
          description: Maximum number of results to return (max 100)
          schema:
            maximum: 100
            minimum: 1
            type: integer
            default: 10
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/EvaluationJob'
        '400':
          description: Bad request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
  /evaluations/model-list:
    get:
      tags:
        - Evaluations
      summary: Get allowed models list
      description: Get the list of models that are allowed for evaluation
      operationId: evaluations-model-list
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  model_list:
                    type: array
                    items:
                      type: string
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
  /files:
    get:
      tags:
        - Files
      summary: List all files
      description: List the metadata for all uploaded data files.
      responses:
        '200':
          description: List of files
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileList'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.files.list()\n\nfor file in response.data:\n    print(file.id)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.files.list();\n\nfor (const file of response.data) {\n  console.log(file.id);\n}\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.files.list();\n\nfor (const file of response.data) {\n  console.log(file.id);\n}\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/files\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
  /files/multipart/abort:
    post:
      tags:
        - Files
      summary: Abort multipart upload
      description: Abort a multipart upload and clean up any uploaded parts.
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/MultipartAbortRequest'
        required: true
      responses:
        '200':
          description: Multipart upload aborted successfully
          content:
            application/json:
              schema:
                type: object
                properties:
                  success:
                    type: boolean
                    example: true
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nclient.files.multipart.abort(\n    upload_id=\"upload-123\",\n    file_id=\"file-456\"\n)\n"
  /files/multipart/complete:
    post:
      tags:
        - Files
      summary: Complete multipart upload
      description: Complete a multipart upload by providing ETags for all uploaded parts.
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/MultipartCompleteRequest'
        required: true
      responses:
        '200':
          description: Multipart upload completed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileResponse'
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.files.multipart.complete(\n    upload_id=\"upload-123\",\n    file_id=\"file-456\",\n    parts=[\n        {\"PartNumber\": 1, \"ETag\": \"etag1\"},\n        {\"PartNumber\": 2, \"ETag\": \"etag2\"}\n    ]\n)\n\nprint(response.id)\n"
  /files/multipart/initiate:
    post:
      tags:
        - Files
      summary: Initiate multipart upload
      description: Initiate a multipart upload for large files (>5GB) with presigned URLs for each part.
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/MultipartInitiateRequest'
        required: true
      responses:
        '200':
          description: Multipart upload initiated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MultipartInitiateResponse'
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.files.multipart.initiate(\n    filename=\"large_dataset.jsonl\",\n    file_size=7516192768,  # 7GB\n    num_parts=75,\n    purpose=\"fine-tune\",\n    file_type=\"jsonl\"\n)\n\nprint(response.upload_id)\n"
  /files/upload:
    post:
      tags:
        - Files
      summary: Upload a file
      description: 'Upload a file with specified purpose, file name, and file type.'
      requestBody:
        content:
          multipart/form-data:
            schema:
              required:
                - purpose
                - file_name
                - file
              type: object
              properties:
                file:
                  type: string
                  description: The content of the file being uploaded
                  format: binary
                file_name:
                  type: string
                  description: The name of the file being uploaded
                  example: dataset.csv
                file_type:
                  $ref: '#/components/schemas/FileType'
                purpose:
                  $ref: '#/components/schemas/FilePurpose'
        required: true
      responses:
        '200':
          description: File uploaded successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileResponse'
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\nfile_path = os.path.join(current_dir, \"data.jsonl\")\nfile = client.files.upload(file=file_path)\n\nprint(file.id)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import { upload } from \"together-ai/lib/upload\"\nimport path from \"path\";\nimport { fileURLToPath } from \"url\";\n\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.dirname(__filename);\nconst filepath = path.join(__dirname, \"data.jsonl\");\nconst file = await upload(filepath);\n\nconsole.log(file.id);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import { upload } from \"together-ai/lib/upload\"\nimport path from \"path\";\nimport { fileURLToPath } from \"url\";\n\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.dirname(__filename);\nconst filepath = path.join(__dirname, \"data.jsonl\");\nconst file = await upload(filepath);\n\nconsole.log(file.id);\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/files/upload\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -F \"file=@/path/to/data.jsonl\" \\\n     -F \"file_name=data.jsonl\" \\\n     -F \"purpose=fine-tune\"\n"
  '/files/{id}':
    delete:
      tags:
        - Files
      summary: Delete a file
      description: Delete a previously uploaded data file.
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: File deleted successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileDeleteResponse'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.files.delete(id=\"file-id\")\n\nprint(response)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.files.delete(\"file-id\");\n\nconsole.log(response);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.files.delete(\"file-id\");\n\nconsole.log(response);\n"
        - label: cURL
          lang: Shell
          source: "curl -X \"DELETE\" \"https://api.together.xyz/v1/files/file-id\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\"\n"
    get:
      tags:
        - Files
      summary: List file
      description: List the metadata for a single uploaded data file.
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: File retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileResponse'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nfile = client.files.retrieve(id=\"file-id\")\n\nprint(file)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst file = await client.files.retrieve(\"file-id\");\n\nconsole.log(file);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst file = await client.files.retrieve(\"file-id\");\n\nconsole.log(file);\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/files/ID\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
  '/files/{id}/content':
    get:
      tags:
        - Files
      summary: Get file contents
      description: Get the contents of a single uploaded data file.
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: File content retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileObject'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nfile = client.files.retrieve_content(id=\"file-id\")\n\nprint(file.filename)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.files.content(\"file-id\");\nconst content = await response.text();\n\nconsole.log(content);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.files.content(\"file-id\");\nconst content = await response.text();\n\nconsole.log(content);\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/files/file-id/content\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
  /fine-tunes:
    get:
      tags:
        - Fine-tuning
      summary: List all jobs
      description: List the metadata for all fine-tuning jobs. Returns a list of FinetuneResponseTruncated objects.
      responses:
        '200':
          description: List of fine-tune jobs
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneTruncatedList'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.fine_tuning.list()\n\nfor fine_tune in response.data:\n    print(f\"ID: {fine_tune.id}, Status: {fine_tune.status}\")\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.fineTune.list();\n\nfor (const fineTune of response.data) {\n  console.log(fineTune.id, fineTune.status);\n}\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.fineTune.list();\n\nfor (const fineTune of response.data) {\n  console.log(fineTune.id, fineTune.status);\n}\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/fine-tunes\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
    post:
      tags:
        - Fine-tuning
      summary: Create job
      description: Create a fine-tuning job with the provided model and training data.
      requestBody:
        content:
          application/json:
            schema:
              required:
                - training_file
                - model
              type: object
              properties:
                batch_size:
                  oneOf:
                    - type: integer
                    - enum:
                        - max
                      type: string
                  description: 'Number of training examples processed together (larger batches use more memory but may train faster). Defaults to "max". We use training optimizations like packing, so the effective batch size may be different than the value you set.'
                  default: max
                from_checkpoint:
                  type: string
                  description: 'The checkpoint identifier to continue training from a previous fine-tuning job. Format is `{$JOB_ID}` or `{$OUTPUT_MODEL_NAME}` or `{$JOB_ID}:{$STEP}` or `{$OUTPUT_MODEL_NAME}:{$STEP}`. The step value is optional; without it, the final checkpoint will be used.'
                from_hf_model:
                  type: string
                  description: The Hugging Face Hub repo to start training from. Should be as close as possible to the base model (specified by the `model` argument) in terms of architecture and size.
                hf_api_token:
                  type: string
                  description: The API token for the Hugging Face Hub.
                hf_model_revision:
                  type: string
                  description: 'The revision of the Hugging Face Hub model to continue training from. E.g., hf_model_revision=main (default, used if the argument is not provided) or hf_model_revision=''607a30d783dfa663caf39e06633721c8d4cfcd7e'' (specific commit).'
                hf_output_repo_name:
                  type: string
                  description: The name of the Hugging Face repository to upload the fine-tuned model to.
                learning_rate:
                  type: number
                  description: 'Controls how quickly the model adapts to new information (too high may cause instability, too low may slow convergence)'
                  format: float
                  default: 1E-05
                lr_scheduler:
                  $ref: '#/components/schemas/LRScheduler'
                max_grad_norm:
                  type: number
                  description: Max gradient norm to be used for gradient clipping. Set to 0 to disable.
                  format: float
                  default: 1
                model:
                  type: string
                  description: Name of the base model to run fine-tune job on
                n_checkpoints:
                  type: integer
                  description: Number of intermediate model versions saved during training for evaluation
                  default: 1
                n_epochs:
                  type: integer
                  description: Number of complete passes through the training dataset (higher values may improve results but increase cost and risk of overfitting)
                  default: 1
                n_evals:
                  type: integer
                  description: Number of evaluations to be run on a given validation set during training
                  default: 0
                suffix:
                  type: string
                  description: Suffix that will be added to your fine-tuned model name
                train_on_inputs:
                  type: boolean
                  oneOf:
                    - type: boolean
                    - enum:
                        - auto
                      type: string
                  description: Whether to mask the user messages in conversational data or prompts in instruction data.
                  default: auto
                  deprecated: true
                training_file:
                  type: string
                  description: File-ID of a training file uploaded to the Together API
                training_method:
                  type: object
                  oneOf:
                    - $ref: '#/components/schemas/TrainingMethodSFT'
                    - $ref: '#/components/schemas/TrainingMethodDPO'
                  description: The training method to use. 'sft' for Supervised Fine-Tuning or 'dpo' for Direct Preference Optimization.
                training_type:
                  type: object
                  oneOf:
                    - $ref: '#/components/schemas/FullTrainingType'
                    - $ref: '#/components/schemas/LoRATrainingType'
                validation_file:
                  type: string
                  description: File-ID of a validation file uploaded to the Together API
                wandb_api_key:
                  type: string
                  description: Integration key for tracking experiments and model metrics on W&B platform
                wandb_base_url:
                  type: string
                  description: The base URL of a dedicated Weights & Biases instance.
                wandb_name:
                  type: string
                  description: The Weights & Biases name for your run.
                wandb_project_name:
                  type: string
                  description: 'The Weights & Biases project for your run. If not specified, will use `together` as the project name.'
                warmup_ratio:
                  type: number
                  description: The percent of steps at the start of training to linearly increase the learning rate.
                  format: float
                  default: 0
                weight_decay:
                  type: number
                  description: Weight decay. Regularization parameter for the optimizer.
                  format: float
                  default: 0
        required: true
      responses:
        '200':
          description: Fine-tuning job initiated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneResponseTruncated'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.fine_tuning.create(\n    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Reference\",\n    training_file=\"file-id\"\n)\n\nprint(response)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.fineTune.create({\n  model: \"meta-llama/Meta-Llama-3.1-8B-Instruct-Reference\",\n  training_file: \"file-id\",\n});\n\nconsole.log(response);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.fineTune.create({\n  model: \"meta-llama/Meta-Llama-3.1-8B-Instruct-Reference\",\n  training_file: \"file-id\",\n});\n\nconsole.log(response);\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/fine-tunes\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Reference\",\n       \"training_file\": \"file-id\"\n     }'\n"
  '/fine-tunes/{id}':
    delete:
      tags:
        - Fine-tuning
      summary: Delete a fine-tune job
      description: Delete a fine-tuning job.
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
        - name: force
          in: query
          required: true
          schema:
            type: boolean
            default: 
      responses:
        '200':
          description: Fine-tune job deleted successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneDeleteResponse'
        '404':
          description: Fine-tune job not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.fine_tuning.delete(id=\"ft-id\")\n\nprint(response)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.fineTune.delete(\"ft-id\");\n\nconsole.log(response);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.fineTune.delete(\"ft-id\");\n\nconsole.log(response);\n"
        - label: cURL
          lang: Shell
          source: "curl -X \"DELETE\" \"https://api.together.xyz/v1/fine-tunes/ft-id?force=false\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
    get:
      tags:
        - Fine-tuning
      summary: List job
      description: List the metadata for a single fine-tuning job.
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Fine-tune job details retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneResponse'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nfine_tune = client.fine_tuning.retrieve(id=\"ft-id\")\n\nprint(fine_tune)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst fineTune = await client.fineTune.retrieve(\"ft-id\");\n\nconsole.log(fineTune);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst fineTune = await client.fineTune.retrieve(\"ft-id\");\n\nconsole.log(fineTune);\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/fine-tunes/ft-id\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
  '/fine-tunes/{id}/cancel':
    post:
      tags:
        - Fine-tuning
      summary: Cancel job
      description: Cancel a currently running fine-tuning job. Returns a FinetuneResponseTruncated object.
      parameters:
        - name: id
          in: path
          description: Fine-tune ID to cancel. A string that starts with `ft-`.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Successfully cancelled the fine-tuning job.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneResponseTruncated'
        '400':
          description: Invalid request parameters.
        '404':
          description: Fine-tune ID not found.
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.fine_tuning.cancel(id=\"ft-id\")\n\nprint(response)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.fineTune.cancel(\"ft-id\");\n\nconsole.log(response);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.fineTune.cancel(\"ft-id\");\n\nconsole.log(response);\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/fine-tunes/ft-id/cancel\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
  '/fine-tunes/{id}/checkpoints':
    get:
      tags:
        - Fine-tuning
      summary: List checkpoints
      description: List the checkpoints for a single fine-tuning job.
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: List of fine-tune checkpoints
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneListCheckpoints'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\ncheckpoints = client.fine_tuning.list_checkpoints(id=\"ft-id\")\n\nprint(checkpoints)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst checkpoints = await client.fineTune.retrieveCheckpoints(\"ft-id\");\n\nconsole.log(checkpoints);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst checkpoints = await client.fineTune.retrieveCheckpoints(\"ft-id\");\n\nconsole.log(checkpoints);\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/fine-tunes/ft-id/checkpoints\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
  '/fine-tunes/{id}/events':
    get:
      tags:
        - Fine-tuning
      summary: List job events
      description: List the events for a single fine-tuning job.
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: List of fine-tune events
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneListEvents'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nevents = client.fine_tuning.list_events(id=\"ft-id\")\n\nprint(events)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst events = await client.fineTune.listEvents(\"ft-id\");\n\nconsole.log(events);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst events = await client.fineTune.listEvents(\"ft-id\");\n\nconsole.log(events);\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/fine-tunes/ft-id/events\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
  /finetune/download:
    get:
      tags:
        - Fine-tuning
      summary: Download model
      description: Download a compressed fine-tuned model or checkpoint to local disk.
      parameters:
        - name: ft_id
          in: query
          description: Fine-tune ID to download. A string that starts with `ft-`.
          required: true
          schema:
            type: string
        - name: checkpoint_step
          in: query
          description: Specifies step number for checkpoint to download. Ignores `checkpoint` value if set.
          schema:
            type: integer
        - name: checkpoint
          in: query
          description: Specifies checkpoint type to download - `merged` vs `adapter`. This field is required if the checkpoint_step is not set.
          schema:
            enum:
              - merged
              - adapter
            type: string
        - name: output
          in: query
          description: 'Specifies output file name for downloaded model. Defaults to `$PWD/{model_name}.{extension}`.'
          schema:
            type: string
      responses:
        '200':
          description: Successfully downloaded the fine-tuned model or checkpoint.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneDownloadResult'
        '400':
          description: Invalid request parameters.
        '404':
          description: Fine-tune ID not found.
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.fine_tuning.download(id=\"ft-id\")\n\nprint(response)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.fineTune.download({\n  ft_id: \"ft-id\",\n  checkpoint: \"merged\",\n});\n\nconsole.log(response);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.fineTune.download({\n  ft_id: \"ft-id\",\n  checkpoint: \"merged\",\n});\n\nconsole.log(response);\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/finetune/download?ft_id=ft-id&checkpoint=merged\"\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
  /hardware:
    get:
      tags:
        - Hardware
      summary: List available hardware configurations
      description: "Returns a list of available hardware configurations for deploying models. When a model parameter is provided, it returns only hardware configurations compatible with that model, including their current availability status.\n"
      operationId: listHardware
      parameters:
        - name: model
          in: query
          description: "Filter hardware configurations by model compatibility. When provided, the response includes availability status for each compatible configuration.\n"
          schema:
            type: string
          example: meta-llama/Llama-3-70b-chat-hf
      responses:
        '200':
          description: List of available hardware configurations
          content:
            application/json:
              schema:
                required:
                  - object
                  - data
                type: object
                properties:
                  data:
                    type: array
                    items:
                      $ref: '#/components/schemas/HardwareWithStatus'
                  object:
                    enum:
                      - list
                    type: string
        '403':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst hardware = await client.hardware.list();\n\nconsole.log(hardware);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst hardware = await client.hardware.list();\n\nconsole.log(hardware);\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/hardware\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
  /images/generations:
    post:
      tags:
        - Images
      summary: Create image
      description: Use an image model to generate an image for a given prompt.
      requestBody:
        content:
          application/json:
            schema:
              required:
                - prompt
                - model
              type: object
              properties:
                disable_safety_checker:
                  type: boolean
                  description: 'If true, disables the safety checker for image generation.'
                guidance_scale:
                  type: number
                  description: 'Adjusts the alignment of the generated image with the input prompt. Higher values (e.g., 8-10) make the output more faithful to the prompt, while lower values (e.g., 1-5) encourage more creative freedom.'
                  default: 3.5
                height:
                  type: integer
                  description: Height of the image to generate in number of pixels.
                  default: 1024
                image_loras:
                  type: array
                  items:
                    required:
                      - path
                      - scale
                    type: object
                    properties:
                      path:
                        type: string
                        description: The URL of the LoRA to apply (e.g. https://huggingface.co/strangerzonehf/Flux-Midjourney-Mix2-LoRA).
                      scale:
                        type: number
                        description: The strength of the LoRA's influence. Most LoRA's recommend a value of 1.
                  description: An array of objects that define LoRAs (Low-Rank Adaptations) to influence the generated image.
                image_url:
                  type: string
                  description: URL of an image to use for image models that support it.
                model:
                  type: string
                  anyOf:
                    - enum:
                        - black-forest-labs/FLUX.1-schnell-Free
                        - black-forest-labs/FLUX.1-schnell
                        - black-forest-labs/FLUX.1.1-pro
                      type: string
                    - type: string
                  description: "The model to use for image generation.<br> <br> [See all of Together AI's image models](https://docs.together.ai/docs/serverless-models#image-models)\n"
                  example: black-forest-labs/FLUX.1-schnell
                n:
                  type: integer
                  description: Number of image results to generate.
                  default: 1
                negative_prompt:
                  type: string
                  description: The prompt or prompts not to guide the image generation.
                output_format:
                  enum:
                    - jpeg
                    - png
                  type: string
                  description: The format of the image response. Can be either be `jpeg` or `png`. Defaults to `jpeg`.
                  default: jpeg
                prompt:
                  type: string
                  description: A description of the desired images. Maximum length varies by model.
                  example: 'cat floating in space, cinematic'
                response_format:
                  enum:
                    - base64
                    - url
                  type: string
                  description: Format of the image response. Can be either a base64 string or a URL.
                seed:
                  type: integer
                  description: Seed used for generation. Can be used to reproduce image generations.
                steps:
                  type: integer
                  description: Number of generation steps.
                  default: 20
                width:
                  type: integer
                  description: Width of the image to generate in number of pixels.
                  default: 1024
        required: true
      responses:
        '200':
          description: Image generated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImageResponse'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.images.generate(\n    model=\"black-forest-labs/FLUX.1-schnell\",\n    steps=4,\n    prompt=\"A cartoon of an astronaut riding a horse on the moon\",\n)\n\nprint(response.data[0].url)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.images.create({\n  model: \"black-forest-labs/FLUX.1-schnell\",\n  prompt: \"A cartoon of an astronaut riding a horse on the moon\",\n});\n\nconsole.log(response.data[0].url);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.images.create({\n  model: \"black-forest-labs/FLUX.1-schnell\",\n  prompt: \"A cartoon of an astronaut riding a horse on the moon\",\n});\n\nconsole.log(response.data[0].url);\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/images/generations\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"model\": \"black-forest-labs/FLUX.1-schnell\",\n       \"prompt\": \"A cartoon of an astronaut riding a horse on the moon\"\n     }'\n"
  /jobs:
    get:
      tags:
        - Jobs
      summary: List all jobs
      description: List all jobs and their statuses
      operationId: listJobs
      responses:
        '200':
          description: Jobs retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/JobsInfoSuccessResponse'
  '/jobs/{jobId}':
    get:
      tags:
        - Jobs
      summary: Get job status
      description: Get the status of a specific job
      operationId: getJob
      parameters:
        - name: jobId
          in: path
          description: The ID of the job to retrieve
          required: true
          schema:
            type: string
          example: job-a15dad11-8d8e-4007-97c5-a211304de284
      responses:
        '200':
          description: Job status retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/JobInfoSuccessResponse'
  /models:
    get:
      tags:
        - Models
      summary: List all models
      description: Lists all of Together's open-source models
      operationId: models
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelInfoList'
        '400':
          description: BadRequest
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: NotFound
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: RateLimit
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '504':
          description: Timeout
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nmodels = client.models.list()\n\nfor model in models:\n    print(model.id)\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst models = await client.models.list();\n\nfor (const model of models) {\n  console.log(model.id);\n}\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst models = await client.models.list();\n\nfor (const model of models) {\n  console.log(model.id);\n}\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/models\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
    post:
      tags:
        - Models
      summary: Upload a custom model or adapter
      description: Upload a custom model or adapter from Hugging Face or S3
      operationId: uploadModel
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModelUploadRequest'
        required: true
      responses:
        '200':
          description: Model / adapter upload job created successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelUploadSuccessResponse'
      x-codeSamples:
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.models.upload({\n  model_name: \"My-Fine-Tuned-Model\",\n  model_source: \"https://ml-models.s3.us-west-2.amazonaws.com/models/my-fine-tuned-model.tar.gz\",\n})\n\nconsole.log(response);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.models.upload({\n  model_name: \"My-Fine-Tuned-Model\",\n  model_source: \"https://ml-models.s3.us-west-2.amazonaws.com/models/my-fine-tuned-model.tar.gz\",\n})\n\nconsole.log(response);\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/models\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n        \"model_name\": \"My-Fine-Tuned-Model\",\n        \"model_source\": \"https://ml-models.s3.us-west-2.amazonaws.com/models/my-fine-tuned-model.tar.gz\"\n      }'\n"
  /rerank:
    post:
      tags:
        - Rerank
      summary: Create a rerank request
      description: Query a reranker model
      operationId: rerank
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RerankRequest'
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RerankResponse'
        '400':
          description: BadRequest
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: NotFound
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: RateLimit
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '503':
          description: Overloaded
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '504':
          description: Timeout
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\ndocuments = [\n    {\n        \"title\": \"Llama\",\n        \"text\": \"The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era.\"\n    },\n    {\n        \"title\": \"Panda\",\n        \"text\": \"The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China.\"\n    },\n    {\n        \"title\": \"Guanaco\",\n        \"text\": \"The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations.\"\n    },\n    {\n        \"title\": \"Wild Bactrian camel\",\n        \"text\": \"The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia.\"\n    }\n]\n\nresponse = client.rerank.create(\n    model=\"Salesforce/Llama-Rank-v1\",\n    query=\"What animals can I find near Peru?\",\n    documents=documents,\n)\n\nfor result in response.results:\n    print(f\"Rank: {result.index + 1}\")\n    print(f\"Title: {documents[result.index]['title']}\")\n    print(f\"Text: {documents[result.index]['text']}\")\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst documents = [{\n  \"title\": \"Llama\",\n  \"text\": \"The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era.\"\n},\n{\n  \"title\": \"Panda\",\n  \"text\": \"The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China.\"\n},\n{\n  \"title\": \"Guanaco\",\n  \"text\": \"The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations.\"\n},\n{\n  \"title\": \"Wild Bactrian camel\",\n  \"text\": \"The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia.\"\n}];\n\nconst response = await client.rerank({\n  model: \"Salesforce/Llama-Rank-v1\",\n  query: \"What animals can I find near Peru?\",\n  documents,\n});\n\nfor (const result of response.results) {\n  console.log(`Rank: ${result.index + 1}`);\n  console.log(`Title: ${documents[result.index].title}`);\n  console.log(`Text: ${documents[result.index].text}`);\n}\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst documents = [{\n  \"title\": \"Llama\",\n  \"text\": \"The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era.\"\n},\n{\n  \"title\": \"Panda\",\n  \"text\": \"The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China.\"\n},\n{\n  \"title\": \"Guanaco\",\n  \"text\": \"The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations.\"\n},\n{\n  \"title\": \"Wild Bactrian camel\",\n  \"text\": \"The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia.\"\n}];\n\nconst response = await client.rerank({\n  model: \"Salesforce/Llama-Rank-v1\",\n  query: \"What animals can I find near Peru?\",\n  documents,\n});\n\nfor (const result of response.results) {\n  console.log(`Rank: ${result.index + 1}`);\n  console.log(`Title: ${documents[result.index].title}`);\n  console.log(`Text: ${documents[result.index].text}`);\n}\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/rerank\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"model\": \"Salesforce/Llama-Rank-v1\",\n       \"query\": \"What animals can I find near Peru?\",\n       \"documents\": [{\n          \"title\": \"Llama\",\n          \"text\": \"The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era.\"\n        },\n        {\n          \"title\": \"Panda\",\n          \"text\": \"The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China.\"\n        },\n        {\n          \"title\": \"Guanaco\",\n          \"text\": \"The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations.\"\n        },\n        {\n          \"title\": \"Wild Bactrian camel\",\n          \"text\": \"The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia.\"\n        }]\n     }'\n"
  /tci/execute:
    post:
      tags:
        - Code Interpreter
      description: "Executes the given code snippet and returns the output. Without a session_id, a new session will be created to run the code. If you do pass in a valid session_id, the code will be run in that session. This is useful for running multiple code snippets in the same environment, because dependencies and similar things are persisted\nbetween calls to the same session.\n"
      operationId: tci/execute
      requestBody:
        description: Execute Request
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ExecuteRequest'
      responses:
        '200':
          description: Execute Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ExecuteResponse'
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: "from together import Together\nimport os\n\nclient = Together(\n    api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n)\n\nresponse = client.code_interpreter.run(\n    code=\"print('Hello world!')\",\n    language=\"python\",\n)\n\nprint(response.data.outputs[0].data);\n"
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.codeInterpreter.execute({\n  code: \"print('Hello world!')\",\n  language: \"python\"\n});\n\nconsole.log(response.data?.outputs?.[0]?.data);\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.codeInterpreter.execute({\n  code: \"print('Hello world!')\",\n  language: \"python\"\n});\n\nconsole.log(response.data?.outputs?.[0]?.data);\n"
        - label: cURL
          lang: Shell
          source: "curl -X POST \"https://api.together.xyz/v1/tci/execute\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"code\": \"print(\\'Hello world!\\')\",\n       \"language\": \"python\"\n     }'\n"
  /tci/sessions:
    get:
      tags:
        - Code Interpreter
      description: "Lists all your currently active sessions.\n"
      operationId: sessions/list
      responses:
        '200':
          description: List Response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/SessionListResponse'
      x-codeSamples:
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.codeInterpreter.sessions.list();\n\nfor (const session of response.data?.sessions) {\n  console.log(session.id);\n}\n"
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: "import Together from \"together-ai\";\n\nconst client = new Together({\n  apiKey: process.env.TOGETHER_API_KEY,\n});\n\nconst response = await client.codeInterpreter.sessions.list();\n\nfor (const session of response.data?.sessions) {\n  console.log(session.id);\n}\n"
        - label: cURL
          lang: Shell
          source: "curl \"https://api.together.xyz/v1/tci/sessions\" \\\n     -H \"Authorization: Bearer $TOGETHER_API_KEY\" \\\n     -H \"Content-Type: application/json\"\n"
components:
  schemas:
    AudioFileBinary:
      type: string
      description: Audio file to transcribe
      format: binary
    AudioFileUrl:
      type: string
      description: Public HTTPS URL to audio file
      format: uri
    AudioSpeechRequest:
      required:
        - model
        - input
        - voice
      type: object
      properties:
        input:
          type: string
          description: Input text to generate the audio for
        language:
          enum:
            - en
            - de
            - fr
            - es
            - hi
            - it
            - ja
            - ko
            - nl
            - pl
            - pt
            - ru
            - sv
            - tr
            - zh
          type: string
          description: Language of input text
          default: en
        model:
          anyOf:
            - enum:
                - cartesia/sonic
              type: string
            - type: string
          description: "The name of the model to query.<br> <br> [See all of Together AI's chat models](https://docs.together.ai/docs/serverless-models#audio-models)\n"
          example: cartesia/sonic
        response_encoding:
          enum:
            - pcm_f32le
            - pcm_s16le
            - pcm_mulaw
            - pcm_alaw
          type: string
          description: Audio encoding of response
          default: pcm_f32le
        response_format:
          enum:
            - mp3
            - wav
            - raw
          type: string
          description: The format of audio output
          default: wav
        sample_rate:
          type: number
          description: Sampling rate to use for the output audio
          default: 44100
        stream:
          type: boolean
          description: 'If true, output is streamed for several characters at a time instead of waiting for the full response. The stream terminates with `data: [DONE]`. If false, return the encoded audio as octet stream'
          default: false
        voice:
          anyOf:
            - enum:
                - laidback woman
                - polite man
                - storyteller lady
                - friendly sidekick
              type: string
            - type: string
          description: 'The voice to use for generating the audio. [View all supported voices here](https://docs.together.ai/docs/text-to-speech#voices-available).'
    AudioSpeechStreamChunk:
      required:
        - object
        - model
        - b64
      type: object
      properties:
        b64:
          type: string
          description: base64 encoded audio stream
        model:
          type: string
          example: cartesia/sonic
        object:
          enum:
            - audio.tts.chunk
          type: string
    AudioSpeechStreamEvent:
      required:
        - data
      type: object
      properties:
        data:
          $ref: '#/components/schemas/AudioSpeechStreamChunk'
    AudioSpeechStreamResponse:
      oneOf:
        - $ref: '#/components/schemas/AudioSpeechStreamEvent'
        - $ref: '#/components/schemas/StreamSentinel'
    AudioTranscriptionJsonResponse:
      required:
        - text
      type: object
      properties:
        text:
          type: string
          description: The transcribed text
          example: 'Hello, world!'
    AudioTranscriptionRequest:
      required:
        - file
      type: object
      properties:
        file:
          oneOf:
            - $ref: '#/components/schemas/AudioFileBinary'
            - $ref: '#/components/schemas/AudioFileUrl'
          description: 'Audio file upload or public HTTP/HTTPS URL. Supported formats .wav, .mp3, .m4a, .webm, .flac.'
        language:
          type: string
          description: 'Optional ISO 639-1 language code. If `auto` is provided, language is auto-detected.'
          default: en
          example: en
        model:
          enum:
            - openai/whisper-large-v3
          type: string
          description: Model to use for transcription
          default: openai/whisper-large-v3
        prompt:
          type: string
          description: Optional text to bias decoding.
        response_format:
          enum:
            - json
            - verbose_json
          type: string
          description: The format of the response
          default: json
        temperature:
          maximum: 1.0
          minimum: 0.0
          type: number
          description: Sampling temperature between 0.0 and 1.0
          format: float
          default: 0
        timestamp_granularities:
          oneOf:
            - enum:
                - segment
                - word
              type: string
            - maxItems: 2
              minItems: 1
              uniqueItems: true
              type: array
              items:
                enum:
                  - segment
                  - word
                type: string
          description: Controls level of timestamp detail in verbose_json. Only used when response_format is verbose_json. Can be a single granularity or an array to get multiple levels.
          default: segment
          example: word
    AudioTranscriptionResponse:
      oneOf:
        - $ref: '#/components/schemas/AudioTranscriptionJsonResponse'
        - $ref: '#/components/schemas/AudioTranscriptionVerboseJsonResponse'
    AudioTranscriptionSegment:
      required:
        - id
        - start
        - end
        - text
      type: object
      properties:
        end:
          type: number
          description: End time of the segment in seconds
          format: float
          example: 3.5
        id:
          type: integer
          description: Unique identifier for the segment
          example: 0
        start:
          type: number
          description: Start time of the segment in seconds
          format: float
          example: 0
        text:
          type: string
          description: The text content of the segment
          example: 'Hello, world!'
    AudioTranscriptionVerboseJsonResponse:
      required:
        - task
        - language
        - duration
        - text
        - segments
      type: object
      properties:
        duration:
          type: number
          description: The duration of the audio in seconds
          format: float
          example: 3.5
        language:
          type: string
          description: The language of the audio
          example: english
        segments:
          type: array
          items:
            $ref: '#/components/schemas/AudioTranscriptionSegment'
          description: Array of transcription segments
        task:
          enum:
            - transcribe
            - translate
          type: string
          description: The task performed
          example: transcribe
        text:
          type: string
          description: The transcribed text
          example: 'Hello, world!'
        words:
          type: array
          items:
            $ref: '#/components/schemas/AudioTranscriptionWord'
          description: Array of transcription words (only when timestamp_granularities includes 'word')
    AudioTranscriptionWord:
      required:
        - word
        - start
        - end
      type: object
      properties:
        end:
          type: number
          description: End time of the word in seconds
          format: float
          example: 0.5
        start:
          type: number
          description: Start time of the word in seconds
          format: float
          example: 0
        word:
          type: string
          description: The word
          example: Hello
    AudioTranslationJsonResponse:
      required:
        - text
      type: object
      properties:
        text:
          type: string
          description: The translated text
          example: 'Hello, world!'
    AudioTranslationRequest:
      required:
        - file
      type: object
      properties:
        file:
          oneOf:
            - type: string
              description: Audio file to translate
              format: binary
            - type: string
              description: Public HTTP/HTTPS URL to audio file
              format: uri
          description: 'Audio file upload or public HTTP/HTTPS URL. Supported formats .wav, .mp3, .m4a, .webm, .flac.'
        language:
          type: string
          description: 'Target output language. Optional ISO 639-1 language code. If omitted, language is set to English.'
          default: en
          example: en
        model:
          enum:
            - openai/whisper-large-v3
          type: string
          description: Model to use for translation
          default: openai/whisper-large-v3
        prompt:
          type: string
          description: Optional text to bias decoding.
        response_format:
          enum:
            - json
            - verbose_json
          type: string
          description: The format of the response
          default: json
        temperature:
          maximum: 1.0
          minimum: 0.0
          type: number
          description: Sampling temperature between 0.0 and 1.0
          format: float
          default: 0
        timestamp_granularities:
          oneOf:
            - enum:
                - segment
                - word
              type: string
            - maxItems: 2
              minItems: 1
              uniqueItems: true
              type: array
              items:
                enum:
                  - segment
                  - word
                type: string
          description: Controls level of timestamp detail in verbose_json. Only used when response_format is verbose_json. Can be a single granularity or an array to get multiple levels.
          default: segment
          example: word
    AudioTranslationResponse:
      oneOf:
        - $ref: '#/components/schemas/AudioTranslationJsonResponse'
        - $ref: '#/components/schemas/AudioTranslationVerboseJsonResponse'
    AudioTranslationVerboseJsonResponse:
      required:
        - task
        - language
        - duration
        - text
        - segments
      type: object
      properties:
        duration:
          type: number
          description: The duration of the audio in seconds
          format: float
          example: 3.5
        language:
          type: string
          description: The target language of the translation
          example: english
        segments:
          type: array
          items:
            $ref: '#/components/schemas/AudioTranscriptionSegment'
          description: Array of translation segments
        task:
          enum:
            - transcribe
            - translate
          type: string
          description: The task performed
          example: translate
        text:
          type: string
          description: The translated text
          example: 'Hello, world!'
        words:
          type: array
          items:
            $ref: '#/components/schemas/AudioTranscriptionWord'
          description: Array of translation words (only when timestamp_granularities includes 'word')
    Autoscaling:
      required:
        - min_replicas
        - max_replicas
      type: object
      properties:
        max_replicas:
          type: integer
          description: The maximum number of replicas to scale up to under load
          format: int32
          example: 5
        min_replicas:
          type: integer
          description: 'The minimum number of replicas to maintain, even when there is no load'
          format: int32
          example: 2
      description: Configuration for automatic scaling of replicas based on demand.
    BatchErrorResponse:
      type: object
      properties:
        error:
          type: string
    BatchJob:
      type: object
      properties:
        completed_at:
          type: string
          format: date-time
          example: '2024-01-15T15:45:30.0000000+00:00'
        created_at:
          type: string
          format: date-time
          example: '2024-01-15T14:30:00.0000000+00:00'
        endpoint:
          type: string
          example: /v1/chat/completions
        error:
          type: string
        error_file_id:
          type: string
          example: file-errors456def789jkl
        file_size_bytes:
          type: integer
          description: Size of input file in bytes
          format: int64
          example: 1048576
        id:
          type: string
          format: uuid
          example: 01234567-8901-2345-6789-012345678901
        input_file_id:
          type: string
          example: file-input123abc456def
        job_deadline:
          type: string
          format: date-time
          example: '2024-01-15T15:30:00.0000000+00:00'
        model_id:
          type: string
          description: Model used for processing requests
          example: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
        output_file_id:
          type: string
          example: file-output789xyz012ghi
        progress:
          type: number
          description: Completion progress (0.0 to 100)
          format: float64
          example: 75
        status:
          $ref: '#/components/schemas/BatchJobStatus'
        user_id:
          type: string
          example: user_789xyz012
    BatchJobStatus:
      enum:
        - VALIDATING
        - IN_PROGRESS
        - COMPLETED
        - FAILED
        - EXPIRED
        - CANCELLED
      type: string
      description: Current status of the batch job
      example: IN_PROGRESS
    BatchJobWithWarning:
      type: object
      properties:
        job:
          $ref: '#/components/schemas/BatchJob'
        warning:
          type: string
    ChatCompletionAssistantMessageParam:
      required:
        - role
      type: object
      properties:
        content:
          type: string
          nullable: true
        function_call:
          required:
            - arguments
            - name
          type: object
          properties:
            arguments:
              type: string
            name:
              type: string
          deprecated: true
        name:
          type: string
        role:
          enum:
            - assistant
          type: string
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolChoice'
    ChatCompletionChoice:
      required:
        - index
        - delta
        - finish_reason
      type: object
      properties:
        delta:
          title: ChatCompletionChoiceDelta
          required:
            - role
          type: object
          properties:
            content:
              type: string
              nullable: true
            function_call:
              required:
                - arguments
                - name
              type: object
              properties:
                arguments:
                  type: string
                name:
                  type: string
              nullable: true
              deprecated: true
            reasoning:
              type: string
              nullable: true
            role:
              enum:
                - system
                - user
                - assistant
                - function
                - tool
              type: string
            token_id:
              type: integer
            tool_calls:
              type: array
              items:
                $ref: '#/components/schemas/ToolChoice'
        finish_reason:
          $ref: '#/components/schemas/FinishReason'
        index:
          type: integer
        logprobs:
          $ref: '#/components/schemas/LogprobsPart'
    ChatCompletionChoicesData:
      type: array
      items:
        type: object
        properties:
          finish_reason:
            $ref: '#/components/schemas/FinishReason'
          index:
            type: integer
          logprobs:
            $ref: '#/components/schemas/LogprobsPart'
          message:
            $ref: '#/components/schemas/ChatCompletionMessage'
          seed:
            type: integer
          text:
            type: string
    ChatCompletionChunk:
      required:
        - id
        - object
        - created
        - choices
        - model
      type: object
      properties:
        choices:
          title: ChatCompletionChoices
          type: array
          items:
            required:
              - index
              - delta
              - finish_reason
            type: object
            properties:
              delta:
                title: ChatCompletionChoiceDelta
                required:
                  - role
                type: object
                properties:
                  content:
                    type: string
                    nullable: true
                  function_call:
                    required:
                      - arguments
                      - name
                    type: object
                    properties:
                      arguments:
                        type: string
                      name:
                        type: string
                    nullable: true
                    deprecated: true
                  role:
                    enum:
                      - system
                      - user
                      - assistant
                      - function
                      - tool
                    type: string
                  token_id:
                    type: integer
                  tool_calls:
                    type: array
                    items:
                      $ref: '#/components/schemas/ToolChoice'
              finish_reason:
                $ref: '#/components/schemas/FinishReason'
              index:
                type: integer
              logprobs:
                type: number
                nullable: true
              seed:
                type: integer
                nullable: true
        created:
          type: integer
        id:
          type: string
        model:
          type: string
          example: mistralai/Mixtral-8x7B-Instruct-v0.1
        object:
          enum:
            - chat.completion.chunk
          type: string
        system_fingerprint:
          type: string
        usage:
          $ref: '#/components/schemas/UsageData'
        warnings:
          type: array
          items:
            $ref: '#/components/schemas/InferenceWarning'
    ChatCompletionEvent:
      required:
        - data
      type: object
      properties:
        data:
          $ref: '#/components/schemas/ChatCompletionChunk'
    ChatCompletionFunctionMessageParam:
      required:
        - content
        - role
        - name
      type: object
      properties:
        content:
          type: string
        name:
          type: string
        role:
          enum:
            - function
          type: string
      deprecated: true
    ChatCompletionMessage:
      required:
        - role
        - content
      type: object
      properties:
        content:
          type: string
          nullable: true
        function_call:
          required:
            - arguments
            - name
          type: object
          properties:
            arguments:
              type: string
            name:
              type: string
          deprecated: true
        reasoning:
          type: string
          nullable: true
        role:
          enum:
            - assistant
          type: string
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolChoice'
    ChatCompletionMessageParam:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionSystemMessageParam'
        - $ref: '#/components/schemas/ChatCompletionUserMessageParam'
        - $ref: '#/components/schemas/ChatCompletionAssistantMessageParam'
        - $ref: '#/components/schemas/ChatCompletionToolMessageParam'
        - $ref: '#/components/schemas/ChatCompletionFunctionMessageParam'
    ChatCompletionRequest:
      required:
        - model
        - messages
      type: object
      properties:
        context_length_exceeded_behavior:
          enum:
            - truncate
            - error
          type: string
          description: 'Defined the behavior of the API when max_tokens exceed the maximum context length of the model. When set to ''error'', API will return 400 with appropriate error message. When set to ''truncate'', override the max_tokens with maximum context length of the model.'
          default: error
        echo:
          type: boolean
          description: 'If true, the response will contain the prompt. Can be used with `logprobs` to return prompt logprobs.'
        frequency_penalty:
          type: number
          description: A number between -2.0 and 2.0 where a positive value decreases the likelihood of repeating tokens that have already been mentioned.
          format: float
        function_call:
          oneOf:
            - enum:
                - none
                - auto
              type: string
            - required:
                - name
              type: object
              properties:
                name:
                  type: string
        logit_bias:
          type: object
          additionalProperties:
            type: number
            format: float
          description: Adjusts the likelihood of specific tokens appearing in the generated output.
          example:
            '1024': -10.5
            '105': 21.4
        logprobs:
          maximum: 20
          minimum: 0
          type: integer
          description: 'An integer between 0 and 20 of the top k tokens to return log probabilities for at each generation step, instead of just the sampled token. Log probabilities help assess model confidence in token predictions.'
        max_tokens:
          type: integer
          description: The maximum number of tokens to generate.
        messages:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessageParam'
          description: A list of messages comprising the conversation so far.
        min_p:
          type: number
          description: A number between 0 and 1 that can be used as an alternative to top_p and top-k.
          format: float
        model:
          anyOf:
            - enum:
                - Qwen/Qwen2.5-72B-Instruct-Turbo
                - Qwen/Qwen2.5-7B-Instruct-Turbo
                - meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
                - meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
                - meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
              type: string
            - type: string
          description: "The name of the model to query.<br> <br> [See all of Together AI's chat models](https://docs.together.ai/docs/serverless-models#chat-models)\n"
          example: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
        n:
          maximum: 128
          minimum: 1
          type: integer
          description: The number of completions to generate for each prompt.
        presence_penalty:
          type: number
          description: A number between -2.0 and 2.0 where a positive value increases the likelihood of a model talking about new topics.
          format: float
        reasoning_effort:
          enum:
            - low
            - medium
            - high
          type: string
          description: Controls the level of reasoning effort the model should apply when generating responses. Higher values may result in more thoughtful and detailed responses but may take longer to generate.
          example: medium
        repetition_penalty:
          type: number
          description: A number that controls the diversity of generated text by reducing the likelihood of repeated sequences. Higher values decrease repetition.
        response_format:
          type: object
          properties:
            schema:
              type: object
              description: The schema of the response format.
            type:
              type: string
              description: The type of the response format.
              example: json
          description: An object specifying the format that the model must output.
        safety_model:
          type: string
          description: 'The name of the moderation model used to validate tokens. Choose from the available moderation models found [here](https://docs.together.ai/docs/inference-models#moderation-models).'
          example: safety_model_name
        seed:
          type: integer
          description: Seed value for reproducibility.
          example: 42
        stop:
          type: array
          items:
            type: string
          description: 'A list of string sequences that will truncate (stop) inference text output. For example, "</s>" will stop generation as soon as the model generates the given token.'
        stream:
          type: boolean
          description: 'If true, stream tokens as Server-Sent Events as the model generates them instead of waiting for the full model response. The stream terminates with `data: [DONE]`. If false, return a single JSON object containing the results.'
        temperature:
          type: number
          description: A decimal number from 0-1 that determines the degree of randomness in the response. A temperature less than 1 favors more correctness and is appropriate for question answering or summarization. A value closer to 1 introduces more randomness in the output.
          format: float
        tool_choice:
          oneOf:
            - type: string
              example: tool_name
            - $ref: '#/components/schemas/ToolChoice'
          description: 'Controls which (if any) function is called by the model. By default uses `auto`, which lets the model pick between generating a message or calling a function.'
        tools:
          type: array
          items:
            $ref: '#/components/schemas/ToolsPart'
          description: 'A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for.'
        top_k:
          type: integer
          description: 'An integer that''s used to limit the number of choices for the next predicted word or token. It specifies the maximum number of tokens to consider at each step, based on their probability of occurrence. This technique helps to speed up the generation process and can improve the quality of the generated text by focusing on the most likely options.'
          format: int32
        top_p:
          type: number
          description: A percentage (also called the nucleus parameter) that's used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. It specifies a probability threshold below which all less likely tokens are filtered out. This technique helps maintain diversity and generate more fluent and natural-sounding text.
          format: float
    ChatCompletionResponse:
      required:
        - choices
        - id
        - created
        - model
        - object
      type: object
      properties:
        choices:
          $ref: '#/components/schemas/ChatCompletionChoicesData'
        created:
          type: integer
        id:
          type: string
        model:
          type: string
        object:
          enum:
            - chat.completion
          type: string
        usage:
          $ref: '#/components/schemas/UsageData'
        warnings:
          type: array
          items:
            $ref: '#/components/schemas/InferenceWarning'
    ChatCompletionStream:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionEvent'
        - $ref: '#/components/schemas/StreamSentinel'
    ChatCompletionSystemMessageParam:
      required:
        - content
        - role
      type: object
      properties:
        content:
          type: string
        name:
          type: string
        role:
          enum:
            - system
          type: string
    ChatCompletionToken:
      required:
        - id
        - text
        - logprob
        - special
      type: object
      properties:
        id:
          type: integer
        logprob:
          type: number
        special:
          type: boolean
        text:
          type: string
    ChatCompletionTool:
      required:
        - type
        - function
      type: object
      properties:
        function:
          required:
            - name
          type: object
          properties:
            description:
              type: string
            name:
              type: string
            parameters:
              type: object
        type:
          enum:
            - function
          type: string
    ChatCompletionToolMessageParam:
      required:
        - role
        - content
        - tool_call_id
      type: object
      properties:
        content:
          type: string
        role:
          enum:
            - tool
          type: string
        tool_call_id:
          type: string
    ChatCompletionUserMessageContent:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionUserMessageContentString'
        - $ref: '#/components/schemas/ChatCompletionUserMessageContentMultimodal'
      description: 'The content of the message, which can either be a simple string or a structured format.'
    ChatCompletionUserMessageContentMultimodal:
      type: array
      items:
        type: object
        oneOf:
          - required:
              - type
              - text
            type: object
            properties:
              text:
                type: string
              type:
                enum:
                  - text
                type: string
          - type: object
            properties:
              image_url:
                required:
                  - url
                type: object
                properties:
                  url:
                    type: string
                    description: The URL of the image
              type:
                enum:
                  - image_url
                type: string
          - title: Video
            required:
              - type
              - video_url
            type: object
            properties:
              type:
                enum:
                  - video_url
                type: string
              video_url:
                required:
                  - url
                type: object
                properties:
                  url:
                    type: string
                    description: The URL of the video
          - title: Audio
            required:
              - type
              - audio_url
            type: object
            properties:
              audio_url:
                required:
                  - url
                type: object
                properties:
                  url:
                    type: string
                    description: The URL of the audio
              type:
                enum:
                  - audio_url
                type: string
          - title: Input Audio
            required:
              - type
              - input_audio
            type: object
            properties:
              input_audio:
                required:
                  - data
                  - format
                type: object
                properties:
                  data:
                    type: string
                    description: The base64 encoded audio data
                  format:
                    enum:
                      - wav
                    type: string
                    description: The format of the audio data
              type:
                enum:
                  - input_audio
                type: string
      description: A structured message with mixed content types.
    ChatCompletionUserMessageContentString:
      type: string
      description: A plain text message.
    ChatCompletionUserMessageParam:
      required:
        - content
        - role
      type: object
      properties:
        content:
          $ref: '#/components/schemas/ChatCompletionUserMessageContent'
        name:
          type: string
        role:
          enum:
            - user
          type: string
    CompletionChoice:
      required:
        - index
      type: object
      properties:
        delta:
          title: CompletionChoiceDelta
          required:
            - role
          type: object
          properties:
            content:
              type: string
              nullable: true
            function_call:
              required:
                - arguments
                - name
              type: object
              properties:
                arguments:
                  type: string
                name:
                  type: string
              nullable: true
              deprecated: true
            role:
              enum:
                - system
                - user
                - assistant
                - function
                - tool
              type: string
            token_id:
              type: integer
            tool_calls:
              type: array
              items:
                $ref: '#/components/schemas/ToolChoice'
        index:
          type: integer
        text:
          type: string
    CompletionChoicesData:
      type: array
      items:
        type: object
        properties:
          finish_reason:
            $ref: '#/components/schemas/FinishReason'
          logprobs:
            $ref: '#/components/schemas/LogprobsPart'
          seed:
            type: integer
          text:
            type: string
            example: 'The capital of France is Paris. It''s located in the north-central part of the country and is one of the most populous and visited cities in the world, known for its iconic landmarks like the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, and more. Paris is also the capital of the Île-de-France region and is a major global center for art, fashion, gastronomy, and culture.'
    CompletionChunk:
      required:
        - id
        - token
        - choices
        - usage
        - finish_reason
      type: object
      properties:
        choices:
          title: CompletionChoices
          type: array
          items:
            $ref: '#/components/schemas/CompletionChoice'
        created:
          type: integer
        finish_reason:
          $ref: '#/components/schemas/FinishReason'
        id:
          type: string
        object:
          enum:
            - completion.chunk
          type: string
        seed:
          type: integer
        token:
          $ref: '#/components/schemas/CompletionToken'
        usage:
          $ref: '#/components/schemas/UsageData'
    CompletionEvent:
      required:
        - data
      type: object
      properties:
        data:
          $ref: '#/components/schemas/CompletionChunk'
    CompletionRequest:
      required:
        - model
        - prompt
      type: object
      properties:
        echo:
          type: boolean
          description: 'If true, the response will contain the prompt. Can be used with `logprobs` to return prompt logprobs.'
        frequency_penalty:
          type: number
          description: A number between -2.0 and 2.0 where a positive value decreases the likelihood of repeating tokens that have already been mentioned.
          format: float
        logit_bias:
          type: object
          additionalProperties:
            type: number
            format: float
          description: Adjusts the likelihood of specific tokens appearing in the generated output.
          example:
            '1024': -10.5
            '105': 21.4
        logprobs:
          maximum: 20
          minimum: 0
          type: integer
          description: 'An integer between 0 and 20 of the top k tokens to return log probabilities for at each generation step, instead of just the sampled token. Log probabilities help assess model confidence in token predictions.'
        max_tokens:
          type: integer
          description: The maximum number of tokens to generate.
        min_p:
          type: number
          description: A number between 0 and 1 that can be used as an alternative to top-p and top-k.
          format: float
        model:
          type: string
          anyOf:
            - enum:
                - meta-llama/Llama-2-70b-hf
                - mistralai/Mistral-7B-v0.1
                - mistralai/Mixtral-8x7B-v0.1
                - Meta-Llama/Llama-Guard-7b
              type: string
            - type: string
          description: "The name of the model to query.<br> <br> [See all of Together AI's chat models](https://docs.together.ai/docs/serverless-models#chat-models)\n"
          example: mistralai/Mixtral-8x7B-Instruct-v0.1
        n:
          maximum: 128
          minimum: 1
          type: integer
          description: The number of completions to generate for each prompt.
        presence_penalty:
          type: number
          description: A number between -2.0 and 2.0 where a positive value increases the likelihood of a model talking about new topics.
          format: float
        prompt:
          type: string
          description: A string providing context for the model to complete.
          example: '<s>[INST] What is the capital of France? [/INST]'
        repetition_penalty:
          type: number
          description: A number that controls the diversity of generated text by reducing the likelihood of repeated sequences. Higher values decrease repetition.
          format: float
        safety_model:
          type: string
          anyOf:
            - enum:
                - Meta-Llama/Llama-Guard-7b
              type: string
            - type: string
          description: 'The name of the moderation model used to validate tokens. Choose from the available moderation models found [here](https://docs.together.ai/docs/inference-models#moderation-models).'
          example: safety_model_name
        seed:
          type: integer
          description: Seed value for reproducibility.
          example: 42
        stop:
          type: array
          items:
            type: string
          description: 'A list of string sequences that will truncate (stop) inference text output. For example, "</s>" will stop generation as soon as the model generates the given token.'
        stream:
          type: boolean
          description: 'If true, stream tokens as Server-Sent Events as the model generates them instead of waiting for the full model response. The stream terminates with `data: [DONE]`. If false, return a single JSON object containing the results.'
        temperature:
          type: number
          description: A decimal number from 0-1 that determines the degree of randomness in the response. A temperature less than 1 favors more correctness and is appropriate for question answering or summarization. A value closer to 1 introduces more randomness in the output.
          format: float
        top_k:
          type: integer
          description: 'An integer that''s used to limit the number of choices for the next predicted word or token. It specifies the maximum number of tokens to consider at each step, based on their probability of occurrence. This technique helps to speed up the generation process and can improve the quality of the generated text by focusing on the most likely options.'
          format: int32
        top_p:
          type: number
          description: A percentage (also called the nucleus parameter) that's used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. It specifies a probability threshold below which all less likely tokens are filtered out. This technique helps maintain diversity and generate more fluent and natural-sounding text.
          format: float
    CompletionResponse:
      required:
        - id
        - choices
        - usage
        - created
        - model
        - object
      type: object
      properties:
        choices:
          $ref: '#/components/schemas/CompletionChoicesData'
        created:
          type: integer
        id:
          type: string
        model:
          type: string
        object:
          enum:
            - text.completion
          type: string
        prompt:
          $ref: '#/components/schemas/PromptPart'
        usage:
          $ref: '#/components/schemas/UsageData'
    CompletionStream:
      oneOf:
        - $ref: '#/components/schemas/CompletionEvent'
        - $ref: '#/components/schemas/StreamSentinel'
    CompletionToken:
      required:
        - id
        - text
        - logprob
        - special
      type: object
      properties:
        id:
          type: integer
        logprob:
          type: number
        special:
          type: boolean
        text:
          type: string
    CosineLRSchedulerArgs:
      required:
        - min_lr_ratio
        - num_cycles
      type: object
      properties:
        min_lr_ratio:
          type: number
          description: The ratio of the final learning rate to the peak learning rate
          format: float
          default: 0
        num_cycles:
          type: number
          description: Number or fraction of cycles for the cosine learning rate scheduler
          format: float
          default: 0.5
    CreateBatchRequest:
      required:
        - endpoint
        - input_file_id
      type: object
      properties:
        completion_window:
          type: string
          description: Time window for batch completion (optional)
          example: 24h
        endpoint:
          type: string
          description: The endpoint to use for batch processing
          example: /v1/chat/completions
        input_file_id:
          type: string
          description: ID of the uploaded input file containing batch requests
          example: file-abc123def456ghi789
        model_id:
          type: string
          description: Model to use for processing batch requests
          example: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
        priority:
          type: integer
          description: Priority for batch processing (optional)
          example: 1
    CreateEndpointRequest:
      required:
        - model
        - hardware
        - autoscaling
      type: object
      properties:
        autoscaling:
          $ref: '#/components/schemas/Autoscaling'
        disable_prompt_cache:
          type: boolean
          description: Whether to disable the prompt cache for this endpoint
          default: false
        disable_speculative_decoding:
          type: boolean
          description: Whether to disable speculative decoding for this endpoint
          default: false
        display_name:
          type: string
          description: A human-readable name for the endpoint
          example: My Llama3 70b endpoint
        hardware:
          type: string
          description: The hardware configuration to use for this endpoint
          example: 1x_nvidia_a100_80gb_sxm
        inactive_timeout:
          type: integer
          description: 'The number of minutes of inactivity after which the endpoint will be automatically stopped. Set to null, omit or set to 0 to disable automatic timeout.'
          nullable: true
          example: 60
        model:
          type: string
          description: The model to deploy on this endpoint
          example: meta-llama/Llama-3-8b-chat-hf
        state:
          enum:
            - STARTED
            - STOPPED
          type: string
          description: The desired state of the endpoint
          default: STARTED
          example: STARTED
    DedicatedEndpoint:
      required:
        - object
        - id
        - name
        - display_name
        - model
        - hardware
        - type
        - owner
        - state
        - autoscaling
        - created_at
      type: object
      properties:
        autoscaling:
          $ref: '#/components/schemas/Autoscaling'
        created_at:
          type: string
          description: Timestamp when the endpoint was created
          format: date-time
          example: '2025-02-04T10:43:55.4050000+00:00'
        display_name:
          type: string
          description: Human-readable name for the endpoint
          example: My Llama3 70b endpoint
        hardware:
          type: string
          description: The hardware configuration used for this endpoint
          example: 1x_nvidia_a100_80gb_sxm
        id:
          type: string
          description: Unique identifier for the endpoint
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
        model:
          type: string
          description: The model deployed on this endpoint
          example: meta-llama/Llama-3-8b-chat-hf
        name:
          type: string
          description: System name for the endpoint
          example: devuser/meta-llama/Llama-3-8b-chat-hf-a32b82a1
        object:
          enum:
            - endpoint
          type: string
          description: The type of object
          example: endpoint
        owner:
          type: string
          description: The owner of this endpoint
          example: devuser
        state:
          enum:
            - PENDING
            - STARTING
            - STARTED
            - STOPPING
            - STOPPED
            - ERROR
          type: string
          description: Current state of the endpoint
          example: STARTED
        type:
          enum:
            - dedicated
          type: string
          description: The type of endpoint
          example: dedicated
      description: Details about a dedicated endpoint deployment
    DisplayorExecuteOutput:
      title: DisplayorExecuteOutput
      required:
        - type
        - data
      properties:
        data:
          type: object
          properties:
            application/geo+json:
              type: object
            application/javascript:
              type: string
            application/json:
              type: object
            application/pdf:
              type: string
              format: byte
            application/vnd.vega.v5+json:
              type: object
            application/vnd.vegalite.v4+json:
              type: object
            image/gif:
              type: string
              format: byte
            image/jpeg:
              type: string
              format: byte
            image/png:
              type: string
              format: byte
            image/svg+xml:
              type: string
            text/html:
              type: string
            text/latex:
              type: string
            text/markdown:
              type: string
            text/plain:
              type: string
        type:
          enum:
            - display_data
            - execute_result
          type: string
    EmbeddingsRequest:
      required:
        - model
        - input
      type: object
      properties:
        input:
          oneOf:
            - type: string
              description: A string providing the text for the model to embed.
              example: 'Our solar system orbits the Milky Way galaxy at about 515,000 mph'
            - type: array
              items:
                type: string
                description: A string providing the text for the model to embed.
                example: 'Our solar system orbits the Milky Way galaxy at about 515,000 mph'
          example: 'Our solar system orbits the Milky Way galaxy at about 515,000 mph'
        model:
          type: string
          anyOf:
            - enum:
                - WhereIsAI/UAE-Large-V1
                - BAAI/bge-large-en-v1.5
                - BAAI/bge-base-en-v1.5
                - togethercomputer/m2-bert-80M-8k-retrieval
              type: string
            - type: string
          description: "The name of the embedding model to use.<br> <br> [See all of Together AI's embedding models](https://docs.together.ai/docs/serverless-models#embedding-models)\n"
          example: togethercomputer/m2-bert-80M-8k-retrieval
    EmbeddingsResponse:
      required:
        - object
        - model
        - data
      type: object
      properties:
        data:
          type: array
          items:
            required:
              - index
              - object
              - embedding
            type: object
            properties:
              embedding:
                type: array
                items:
                  type: number
              index:
                type: integer
              object:
                enum:
                  - embedding
                type: string
        model:
          type: string
        object:
          enum:
            - list
          type: string
    EndpointPricing:
      required:
        - cents_per_minute
      type: object
      properties:
        cents_per_minute:
          type: number
          description: Cost per minute of endpoint uptime in cents
          format: float
          example: 5.42
      description: Pricing details for using an endpoint
    Error:
      title: Error
      oneOf:
        - type: string
        - type: object
    ErrorData:
      required:
        - error
      type: object
      properties:
        error:
          required:
            - type
            - message
          type: object
          properties:
            code:
              type: string
              default: 
              nullable: true
            message:
              type: string
            param:
              type: string
              default: 
              nullable: true
            type:
              type: string
    ErrorOutput:
      title: ErrorOutput
      required:
        - type
        - data
      properties:
        data:
          type: string
        type:
          enum:
            - error
          type: string
      description: 'Errors and exceptions that occurred. If this output type is present, your code did not execute successfully.'
    EvaluationClassifyParameters:
      required:
        - judge
        - labels
        - pass_labels
        - input_data_file_path
      type: object
      properties:
        input_data_file_path:
          type: string
          description: Data file ID
          example: file-1234-aefd
        judge:
          $ref: '#/components/schemas/EvaluationJudgeModelConfig'
        labels:
          minItems: 2
          type: array
          items:
            type: string
          description: List of possible classification labels
          example:
            - yes
            - no
        model_to_evaluate:
          $ref: '#/components/schemas/EvaluationModelOrString'
        pass_labels:
          minItems: 1
          type: array
          items:
            type: string
          description: List of labels that are considered passing
          example:
            - yes
    EvaluationClassifyResults:
      type: object
      properties:
        generation_fail_count:
          type: number
          description: Number of failed generations.
          format: integer
          nullable: true
          example: 0
        invalid_label_count:
          type: number
          description: Number of invalid labels
          format: float
          nullable: true
          example: 0
        judge_fail_count:
          type: number
          description: Number of failed judge generations
          format: integer
          nullable: true
          example: 0
        label_counts:
          type: string
          description: JSON string representing label counts
          example: '{"yes": 10, "no": 0}'
        pass_percentage:
          type: number
          description: Pecentage of pass labels.
          format: integer
          nullable: true
          example: 10
        result_file_id:
          type: string
          description: Data File ID
          example: file-1234-aefd
    EvaluationCompareParameters:
      required:
        - judge
        - input_data_file_path
      type: object
      properties:
        input_data_file_path:
          type: string
          description: Data file name
        judge:
          $ref: '#/components/schemas/EvaluationJudgeModelConfig'
        model_a:
          $ref: '#/components/schemas/EvaluationModelOrString'
        model_b:
          $ref: '#/components/schemas/EvaluationModelOrString'
    EvaluationCompareResults:
      type: object
      properties:
        A_wins:
          type: integer
          description: Number of times model A won
        B_wins:
          type: integer
          description: Number of times model B won
        Ties:
          type: integer
          description: Number of ties
        generation_fail_count:
          type: number
          description: Number of failed generations.
          format: integer
          nullable: true
          example: 0
        judge_fail_count:
          type: number
          description: Number of failed judge generations
          format: integer
          nullable: true
          example: 0
        num_samples:
          type: integer
          description: Total number of samples compared
        result_file_id:
          type: string
          description: Data File ID
    EvaluationJob:
      type: object
      properties:
        created_at:
          type: string
          description: When the job was created
          format: date-time
          example: '2025-07-23T17:10:04.8378880+00:00'
        owner_id:
          type: string
          description: ID of the job owner (admin only)
        parameters:
          type: object
          description: The parameters used for this evaluation
        results:
          oneOf:
            - $ref: '#/components/schemas/EvaluationClassifyResults'
            - $ref: '#/components/schemas/EvaluationScoreResults'
            - $ref: '#/components/schemas/EvaluationCompareResults'
            - type: object
              properties:
                error:
                  type: string
          description: Results of the evaluation (when completed)
          nullable: true
        status:
          enum:
            - pending
            - queued
            - running
            - completed
            - error
            - user_error
          type: string
          description: Current status of the job
          example: completed
        status_updates:
          type: array
          items:
            $ref: '#/components/schemas/EvaluationJobStatusUpdate'
          description: History of status updates (admin only)
        type:
          enum:
            - classify
            - score
            - compare
          type: string
          description: The type of evaluation
          example: classify
        updated_at:
          type: string
          description: When the job was last updated
          format: date-time
          example: '2025-07-23T17:10:04.8378880+00:00'
        workflow_id:
          type: string
          description: The evaluation job ID
          example: eval-1234aedf
    EvaluationJobStatusUpdate:
      type: object
      properties:
        message:
          type: string
          description: Additional message for this update
          example: Job is pending evaluation
        status:
          type: string
          description: The status at this update
          example: pending
        timestamp:
          type: string
          description: When this update occurred
          format: date-time
          example: '2025-07-23T17:10:04.8378880+00:00'
    EvaluationJudgeModelConfig:
      required:
        - model_name
        - system_template
      type: object
      properties:
        model_name:
          type: string
          description: Name of the judge model
          example: meta-llama/Llama-3-70B-Instruct-Turbo
        system_template:
          type: string
          description: System prompt template for the judge
          example: Imagine you are a helpful assistant
    EvaluationModelOrString:
      oneOf:
        - type: string
          description: Field name in the input data
        - $ref: '#/components/schemas/EvaluationModelRequest'
    EvaluationModelRequest:
      required:
        - model_name
        - max_tokens
        - temperature
        - system_template
        - input_template
      type: object
      properties:
        input_template:
          type: string
          description: Input prompt template
          example: 'Please classify {{prompt}} based on the labels below'
        max_tokens:
          minimum: 1
          type: integer
          description: Maximum number of tokens to generate
          example: 512
        model_name:
          type: string
          description: Name of the model to evaluate
          example: meta-llama/Llama-3-70B-Instruct-Turbo
        system_template:
          type: string
          description: System prompt template
          example: Imagine you are helpful assistant
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: Sampling temperature
          format: float
          example: 0.7
    EvaluationResponse:
      type: object
      properties:
        status:
          enum:
            - pending
          type: string
          description: Initial status of the job
        workflow_id:
          type: string
          description: The ID of the created evaluation job
          example: eval-1234-1244513
    EvaluationScoreParameters:
      required:
        - judge
        - min_score
        - max_score
        - pass_threshold
        - input_data_file_path
      type: object
      properties:
        input_data_file_path:
          type: string
          description: Data file ID
          example: file-01234567890123456789
        judge:
          $ref: '#/components/schemas/EvaluationJudgeModelConfig'
        max_score:
          type: number
          description: Maximum possible score
          format: float
          example: 10
        min_score:
          type: number
          description: Minimum possible score
          format: float
          example: 0
        model_to_evaluate:
          $ref: '#/components/schemas/EvaluationModelOrString'
        pass_threshold:
          type: number
          description: Score threshold for passing
          format: float
          example: 7
    EvaluationScoreResults:
      type: object
      properties:
        aggregated_scores:
          type: object
          properties:
            mean_score:
              type: number
              format: float
            pass_percentage:
              type: number
              format: float
            std_score:
              type: number
              format: float
        failed_samples:
          type: number
          description: number of failed samples generated from model
          format: integer
        generation_fail_count:
          type: number
          description: Number of failed generations.
          format: integer
          nullable: true
          example: 0
        invalid_score_count:
          type: number
          description: number of invalid scores generated from model
          format: integer
        judge_fail_count:
          type: number
          description: Number of failed judge generations
          format: integer
          nullable: true
          example: 0
        result_file_id:
          type: string
          description: Data File ID
          example: file-1234-aefd
    EvaluationTypedRequest:
      required:
        - type
        - parameters
      type: object
      properties:
        parameters:
          oneOf:
            - $ref: '#/components/schemas/EvaluationClassifyParameters'
            - $ref: '#/components/schemas/EvaluationScoreParameters'
            - $ref: '#/components/schemas/EvaluationCompareParameters'
          description: Type-specific parameters for the evaluation
        type:
          enum:
            - classify
            - score
            - compare
          type: string
          description: The type of evaluation to perform
          example: classify
    ExecuteRequest:
      title: ExecuteRequest
      required:
        - language
        - code
      properties:
        code:
          type: string
          description: Code snippet to execute.
          example: 'print(''Hello, world!'')'
        files:
          type: array
          items:
            required:
              - name
              - encoding
              - content
            type: object
            properties:
              content:
                type: string
              encoding:
                enum:
                  - string
                  - base64
                type: string
                description: 'Encoding of the file content. Use `string` for text files such as code, and `base64` for binary files, such as images.'
              name:
                type: string
          description: 'Files to upload to the session. If present, files will be uploaded before executing the given code.'
        language:
          enum:
            - python
          description: 'Programming language for the code to execute. Currently only supports Python, but more will be added.'
          default: python
        session_id:
          type: string
          description: Identifier of the current session. Used to make follow-up calls. Requests will return an error if the session does not belong to the caller or has expired.
          example: ses_abcDEF123
    ExecuteResponse:
      title: ExecuteResponse
      type: object
      oneOf:
        - title: SuccessfulExecution
          required:
            - data
            - errors
          type: object
          properties:
            data:
              required:
                - session_id
                - outputs
              type: object
              properties:
                outputs:
                  type: array
                  items:
                    title: InterpreterOutput
                    oneOf:
                      - title: StreamOutput
                        required:
                          - type
                          - data
                        type: object
                        properties:
                          data:
                            type: string
                          type:
                            enum:
                              - stdout
                              - stderr
                            type: string
                        description: Outputs that were printed to stdout or stderr
                      - title: ErrorOutput
                        required:
                          - type
                          - data
                        properties:
                          data:
                            type: string
                          type:
                            enum:
                              - error
                            type: string
                        description: 'Errors and exceptions that occurred. If this output type is present, your code did not execute successfully.'
                      - title: DisplayorExecuteOutput
                        required:
                          - type
                          - data
                        properties:
                          data:
                            type: object
                            properties:
                              application/geo+json:
                                type: object
                              application/javascript:
                                type: string
                              application/json:
                                type: object
                              application/pdf:
                                type: string
                                format: byte
                              application/vnd.vega.v5+json:
                                type: object
                              application/vnd.vegalite.v4+json:
                                type: object
                              image/gif:
                                type: string
                                format: byte
                              image/jpeg:
                                type: string
                                format: byte
                              image/png:
                                type: string
                                format: byte
                              image/svg+xml:
                                type: string
                              text/html:
                                type: string
                              text/latex:
                                type: string
                              text/markdown:
                                type: string
                              text/plain:
                                type: string
                          type:
                            enum:
                              - display_data
                              - execute_result
                            type: string
                    discriminator:
                      propertyName: type
                session_id:
                  type: string
                  description: Identifier of the current session. Used to make follow-up calls.
                  example: ses_abcDEF123
                status:
                  enum:
                    - success
                  type: string
                  description: Status of the execution. Currently only supports success.
            errors:
              type: 'null'
        - title: FailedExecution
          required:
            - data
            - errors
          type: object
          properties:
            data:
              type: 'null'
            errors:
              type: array
              items:
                title: Error
                oneOf:
                  - type: string
                  - type: object
      description: 'The result of the execution. If successful, `data` contains the result and `errors` will be null. If unsuccessful, `data` will be null and `errors` will contain the errors.'
    FileDeleteResponse:
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
    FileList:
      required:
        - data
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FileResponse'
    FileObject:
      type: object
      properties:
        filename:
          type: string
        id:
          type: string
        object:
          type: string
        size:
          type: integer
    FilePurpose:
      enum:
        - fine-tune
        - eval
        - eval-sample
        - eval-output
        - eval-summary
        - batch-generated
        - batch-api
      type: string
      description: The purpose of the file
      example: fine-tune
    FileResponse:
      required:
        - id
        - object
        - created_at
        - filename
        - bytes
        - purpose
        - FileType
        - Processed
        - LineCount
      type: object
      properties:
        FileType:
          $ref: '#/components/schemas/FileType'
        LineCount:
          type: integer
        Processed:
          type: boolean
        bytes:
          type: integer
          example: 2664
        created_at:
          type: integer
          example: 1715021438
        filename:
          type: string
          example: my_file.jsonl
        id:
          type: string
        object:
          type: string
          example: file
        purpose:
          $ref: '#/components/schemas/FilePurpose'
    FileType:
      enum:
        - csv
        - jsonl
        - parquet
      type: string
      description: The type of the file
      default: jsonl
      example: jsonl
    FineTuneCheckpoint:
      required:
        - step
        - path
        - created_at
        - checkpoint_type
      type: object
      properties:
        checkpoint_type:
          type: string
        created_at:
          type: string
        path:
          type: string
        step:
          type: integer
    FineTuneEvent:
      required:
        - object
        - created_at
        - message
        - type
        - param_count
        - token_count
        - total_steps
        - wandb_url
        - step
        - checkpoint_path
        - model_path
        - training_offset
        - hash
      type: object
      properties:
        checkpoint_path:
          type: string
        created_at:
          type: string
        hash:
          type: string
        level:
          anyOf:
            - $ref: '#/components/schemas/FinetuneEventLevels'
        message:
          type: string
        model_path:
          type: string
        object:
          enum:
            - fine-tune-event
          type: string
        param_count:
          type: integer
        step:
          type: integer
        token_count:
          type: integer
        total_steps:
          type: integer
        training_offset:
          type: integer
        type:
          $ref: '#/components/schemas/FinetuneEventType'
        wandb_url:
          type: string
    FinetuneDeleteResponse:
      type: object
      properties:
        message:
          type: string
          description: Message indicating the result of the deletion
    FinetuneDownloadResult:
      type: object
      properties:
        checkpoint_step:
          type: integer
        filename:
          type: string
        id:
          type: string
        object:
          enum:
            - local
          nullable: true
        size:
          type: integer
    FinetuneEventLevels:
      enum:
        - info
        - warning
        - error
        - legacy_info
        - legacy_iwarning
        - legacy_ierror
      type: string
      nullable: true
    FinetuneEventType:
      enum:
        - job_pending
        - job_start
        - job_stopped
        - model_downloading
        - model_download_complete
        - training_data_downloading
        - training_data_download_complete
        - validation_data_downloading
        - validation_data_download_complete
        - wandb_init
        - training_start
        - checkpoint_save
        - billing_limit
        - epoch_complete
        - training_complete
        - model_compressing
        - model_compression_complete
        - model_uploading
        - model_upload_complete
        - job_complete
        - job_error
        - cancel_requested
        - job_restarted
        - refund
        - warning
      type: string
    FinetuneJobStatus:
      enum:
        - pending
        - queued
        - running
        - compressing
        - uploading
        - cancel_requested
        - cancelled
        - error
        - completed
      type: string
    FinetuneListCheckpoints:
      required:
        - data
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuneCheckpoint'
    FinetuneListEvents:
      required:
        - data
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuneEvent'
    FinetuneResponse:
      required:
        - id
        - status
      type: object
      properties:
        batch_size:
          oneOf:
            - type: integer
            - enum:
                - max
              type: string
          default: max
        created_at:
          type: string
        epochs_completed:
          type: integer
        eval_steps:
          type: integer
        events:
          type: array
          items:
            $ref: '#/components/schemas/FineTuneEvent'
        from_checkpoint:
          type: string
        from_hf_model:
          type: string
        hf_model_revision:
          type: string
        id:
          type: string
          format: uuid
        job_id:
          type: string
        learning_rate:
          type: number
        lr_scheduler:
          $ref: '#/components/schemas/LRScheduler'
        max_grad_norm:
          type: number
          format: float
        model:
          type: string
        model_output_name:
          type: string
        model_output_path:
          type: string
        n_checkpoints:
          type: integer
        n_epochs:
          type: integer
        n_evals:
          type: integer
        param_count:
          type: integer
        queue_depth:
          type: integer
        status:
          $ref: '#/components/schemas/FinetuneJobStatus'
        token_count:
          type: integer
        total_price:
          type: integer
        train_on_inputs:
          oneOf:
            - type: boolean
            - enum:
                - auto
              type: string
          default: auto
        training_file:
          type: string
        training_method:
          type: object
          oneOf:
            - $ref: '#/components/schemas/TrainingMethodSFT'
            - $ref: '#/components/schemas/TrainingMethodDPO'
        training_type:
          type: object
          oneOf:
            - $ref: '#/components/schemas/FullTrainingType'
            - $ref: '#/components/schemas/LoRATrainingType'
        trainingfile_numlines:
          type: integer
        trainingfile_size:
          type: integer
        updated_at:
          type: string
        validation_file:
          type: string
        wandb_project_name:
          type: string
        wandb_url:
          type: string
        warmup_ratio:
          type: number
        weight_decay:
          type: number
          format: float
    FinetuneResponseTruncated:
      required:
        - id
        - status
        - created_at
        - updated_at
      type: object
      properties:
        batch_size:
          type: integer
          description: Batch size used for training
        created_at:
          type: string
          description: Creation timestamp of the fine-tune job
          format: date-time
        events:
          type: array
          items:
            $ref: '#/components/schemas/FineTuneEvent'
          description: Events related to this fine-tune job
        from_checkpoint:
          type: string
          description: Checkpoint used to continue training
        from_hf_model:
          type: string
          description: Hugging Face Hub repo to start training from
        hf_model_revision:
          type: string
          description: The revision of the Hugging Face Hub model to continue training from
        id:
          type: string
          description: Unique identifier for the fine-tune job
        learning_rate:
          type: number
          description: Learning rate used for training
          format: float
        lr_scheduler:
          $ref: '#/components/schemas/LRScheduler'
        max_grad_norm:
          type: number
          description: Maximum gradient norm for clipping
          format: float
        model:
          type: string
          description: Base model used for fine-tuning
        model_output_name:
          type: string
        n_checkpoints:
          type: integer
          description: Number of checkpoints saved during training
        n_epochs:
          type: integer
          description: Number of training epochs
        n_evals:
          type: integer
          description: Number of evaluations during training
        owner_address:
          type: string
          description: Owner address information
        status:
          $ref: '#/components/schemas/FinetuneJobStatus'
        suffix:
          type: string
          description: Suffix added to the fine-tuned model name
        token_count:
          type: integer
          description: Count of tokens processed
        total_price:
          type: integer
          description: Total price for the fine-tuning job
        training_file:
          type: string
          description: File-ID of the training file
        training_method:
          oneOf:
            - $ref: '#/components/schemas/TrainingMethodSFT'
            - $ref: '#/components/schemas/TrainingMethodDPO'
          description: Method of training used
        training_type:
          oneOf:
            - $ref: '#/components/schemas/FullTrainingType'
            - $ref: '#/components/schemas/LoRATrainingType'
          description: Type of training used (full or LoRA)
        updated_at:
          type: string
          description: Last update timestamp of the fine-tune job
          format: date-time
        user_id:
          type: string
          description: Identifier for the user who created the job
        validation_file:
          type: string
          description: File-ID of the validation file
        wandb_name:
          type: string
          description: Weights & Biases run name
        wandb_project_name:
          type: string
          description: Weights & Biases project name
        warmup_ratio:
          type: number
          description: Ratio of warmup steps
          format: float
        weight_decay:
          type: number
          description: Weight decay value used
          format: float
      description: 'A truncated version of the fine-tune response, used for POST /fine-tunes, GET /fine-tunes and POST /fine-tunes/{id}/cancel endpoints'
      example:
        created_at: '2023-05-17T17:35:45.1230000+00:00'
        events: [ ]
        id: ft-01234567890123456789
        model: meta-llama/Llama-2-7b-hf
        model_output_name: mynamespace/meta-llama/Llama-2-7b-hf-32162631
        n_epochs: 3
        owner_address: user@example.com
        status: completed
        token_count: 850000
        total_price: 1500
        training_file: file-01234567890123456789
        updated_at: '2023-05-17T18:46:23.4560000+00:00'
        user_id: user_01234567890123456789
        wandb_project_name: my-finetune-project
    FinetuneTruncatedList:
      required:
        - data
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FinetuneResponseTruncated'
    FinishReason:
      enum:
        - stop
        - eos
        - length
        - tool_calls
        - function_call
      type: string
    FullTrainingType:
      required:
        - type
      type: object
      properties:
        type:
          enum:
            - Full
          type: string
    HardwareAvailability:
      required:
        - status
      type: object
      properties:
        status:
          enum:
            - available
            - unavailable
            - insufficient
          type: string
          description: The availability status of the hardware configuration
      description: Indicates the current availability status of a hardware configuration
    HardwareSpec:
      required:
        - gpu_type
        - gpu_link
        - gpu_memory
        - gpu_count
      type: object
      properties:
        gpu_count:
          type: integer
          description: Number of GPUs in this configuration
          format: int32
          example: 2
        gpu_link:
          type: string
          description: The GPU interconnect technology
          example: sxm
        gpu_memory:
          type: number
          description: Amount of GPU memory in GB
          format: float
          example: 80
        gpu_type:
          type: string
          description: The type/model of GPU
          example: a100-80gb
      description: Detailed specifications of a hardware configuration
    HardwareWithStatus:
      required:
        - object
        - id
        - pricing
        - specs
        - updated_at
      type: object
      properties:
        availability:
          $ref: '#/components/schemas/HardwareAvailability'
        id:
          type: string
          description: Unique identifier for the hardware configuration
          example: 2x_nvidia_a100_80gb_sxm
        object:
          enum:
            - hardware
          type: string
        pricing:
          $ref: '#/components/schemas/EndpointPricing'
        specs:
          $ref: '#/components/schemas/HardwareSpec'
        updated_at:
          type: string
          description: Timestamp of when the hardware status was last updated
          format: date-time
      description: Hardware configuration details with optional availability status
    ImageResponse:
      required:
        - id
        - model
        - object
        - data
      type: object
      properties:
        data:
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/ImageResponseDataB64'
              - $ref: '#/components/schemas/ImageResponseDataUrl'
            discriminator:
              propertyName: type
        id:
          type: string
        model:
          type: string
        object:
          enum:
            - list
          example: list
    ImageResponseDataB64:
      required:
        - index
        - b64_json
        - type
      type: object
      properties:
        b64_json:
          type: string
        index:
          type: integer
        type:
          enum:
            - b64_json
          type: string
    ImageResponseDataUrl:
      required:
        - index
        - url
        - type
      type: object
      properties:
        index:
          type: integer
        type:
          enum:
            - url
          type: string
        url:
          type: string
    InferenceWarning:
      required:
        - message
      type: object
      properties:
        message:
          type: string
    InterpreterOutput:
      title: InterpreterOutput
      oneOf:
        - title: StreamOutput
          required:
            - type
            - data
          properties:
            data:
              type: string
            type:
              enum:
                - stdout
                - stderr
              type: string
          description: Outputs that were printed to stdout or stderr
        - title: ErrorOutput
          required:
            - type
            - data
          properties:
            data:
              type: string
            type:
              enum:
                - error
              type: string
          description: 'Errors and exceptions that occurred. If this output type is present, your code did not execute successfully.'
        - title: DisplayorExecuteOutput
          required:
            - type
            - data
          properties:
            data:
              type: object
              properties:
                application/geo+json:
                  type: object
                application/javascript:
                  type: string
                application/json:
                  type: object
                application/pdf:
                  type: string
                  format: byte
                application/vnd.vega.v5+json:
                  type: object
                application/vnd.vegalite.v4+json:
                  type: object
                image/gif:
                  type: string
                  format: byte
                image/jpeg:
                  type: string
                  format: byte
                image/png:
                  type: string
                  format: byte
                image/svg+xml:
                  type: string
                text/html:
                  type: string
                text/latex:
                  type: string
                text/markdown:
                  type: string
                text/plain:
                  type: string
            type:
              enum:
                - display_data
                - execute_result
              type: string
      discriminator:
        propertyName: type
    JobInfoSuccessResponse:
      required:
        - type
        - job_id
        - status
        - status_updates
        - args
        - created_at
        - updated_at
      type: object
      properties:
        args:
          type: object
          properties:
            description:
              type: string
              example: Finetuned Qwen2.5-72B-Instruct by Unsloth
            modelName:
              type: string
              example: necolinehubner/Qwen2.5-72B-Instruct
            modelSource:
              type: string
              example: unsloth/Qwen2.5-72B-Instruct
        created_at:
          type: string
          format: date-time
          example: '2025-03-11T22:05:43.0000000+00:00'
        job_id:
          type: string
          example: job-a15dad11-8d8e-4007-97c5-a211304de284
        status:
          enum:
            - Queued
            - Running
            - Complete
            - Failed
          type: string
          example: Complete
        status_updates:
          type: array
          items:
            required:
              - status
              - message
              - timestamp
            type: object
            properties:
              message:
                type: string
                example: Job is Complete
              status:
                type: string
                example: Complete
              timestamp:
                type: string
                format: date-time
                example: '2025-03-11T22:36:12.0000000+00:00'
        type:
          type: string
          example: model_upload
        updated_at:
          type: string
          format: date-time
          example: '2025-03-11T22:36:12.0000000+00:00'
    JobsInfoSuccessResponse:
      required:
        - data
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/JobInfoSuccessResponse'
    LRScheduler:
      required:
        - lr_scheduler_type
      type: object
      properties:
        lr_scheduler_args:
          oneOf:
            - $ref: '#/components/schemas/LinearLRSchedulerArgs'
            - $ref: '#/components/schemas/CosineLRSchedulerArgs'
        lr_scheduler_type:
          enum:
            - linear
            - cosine
          type: string
    LinearLRSchedulerArgs:
      type: object
      properties:
        min_lr_ratio:
          type: number
          description: The ratio of the final learning rate to the peak learning rate
          format: float
          default: 0
    ListEndpoint:
      required:
        - id
        - object
        - name
        - model
        - type
        - owner
        - state
        - created_at
      type: object
      properties:
        created_at:
          type: string
          description: Timestamp when the endpoint was created
          format: date-time
          example: '2024-02-28T21:34:35.4440000+00:00'
        id:
          type: string
          description: Unique identifier for the endpoint
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
        model:
          type: string
          description: The model deployed on this endpoint
          example: allenai/OLMo-7B
        name:
          type: string
          description: System name for the endpoint
          example: allenai/OLMo-7B
        object:
          enum:
            - endpoint
          type: string
          description: The type of object
          example: endpoint
        owner:
          type: string
          description: The owner of this endpoint
          example: together
        state:
          enum:
            - PENDING
            - STARTING
            - STARTED
            - STOPPING
            - STOPPED
            - ERROR
          type: string
          description: Current state of the endpoint
          example: STARTED
        type:
          enum:
            - serverless
            - dedicated
          type: string
          description: The type of endpoint
          example: serverless
      description: Details about an endpoint when listed via the list endpoint
    LoRATrainingType:
      required:
        - type
        - lora_r
        - lora_alpha
      type: object
      properties:
        lora_alpha:
          type: integer
        lora_dropout:
          type: number
          format: float
          default: 0
        lora_r:
          type: integer
        lora_trainable_modules:
          type: string
          default: all-linear
        type:
          enum:
            - Lora
          type: string
    LogprobsPart:
      type: object
      properties:
        token_ids:
          type: array
          items:
            type: number
          description: List of token IDs corresponding to the logprobs
        token_logprobs:
          type: array
          items:
            type: number
          description: List of token log probabilities
        tokens:
          type: array
          items:
            type: string
          description: List of token strings
    ModelInfo:
      required:
        - id
        - object
        - created
        - type
      type: object
      properties:
        context_length:
          type: integer
          example: 2048
        created:
          type: integer
          example: 1692896905
        display_name:
          type: string
          example: Chronos Hermes (13B)
        id:
          type: string
          example: Austism/chronos-hermes-13b
        license:
          type: string
          example: other
        link:
          type: string
        object:
          type: string
          example: model
        organization:
          type: string
          example: Austism
        pricing:
          $ref: '#/components/schemas/Pricing'
        type:
          enum:
            - chat
            - language
            - code
            - image
            - embedding
            - moderation
            - rerank
          example: chat
    ModelInfoList:
      type: array
      items:
        $ref: '#/components/schemas/ModelInfo'
    ModelUploadRequest:
      required:
        - model_name
        - model_source
      type: object
      properties:
        base_model:
          type: string
          description: The base model to use for an adapter if setting it to run against a serverless pool.  Only used for model_type `adapter`.
          example: Qwen/Qwen2.5-72B-Instruct
        description:
          type: string
          description: A description of your model
          example: Finetuned Qwen2.5-72B-Instruct by Unsloth
        hf_token:
          type: string
          description: Hugging Face token (if uploading from Hugging Face)
          example: hf_examplehuggingfacetoken
        lora_model:
          type: string
          description: 'The lora pool to use for an adapter if setting it to run against, say, a dedicated pool.  Only used for model_type `adapter`.'
          example: my_username/Qwen2.5-72B-Instruct-lora
        model_name:
          type: string
          description: The name to give to your uploaded model
          example: Qwen2.5-72B-Instruct
        model_source:
          type: string
          description: The source location of the model (Hugging Face repo or S3 path)
          example: unsloth/Qwen2.5-72B-Instruct
        model_type:
          enum:
            - model
            - adapter
          type: string
          description: Whether the model is a full model or an adapter
          default: model
          example: model
    ModelUploadSuccessResponse:
      required:
        - data
        - message
      type: object
      properties:
        data:
          required:
            - job_id
            - model_name
            - model_id
            - model_source
          type: object
          properties:
            job_id:
              type: string
              example: job-a15dad11-8d8e-4007-97c5-a211304de284
            model_id:
              type: string
              example: model-c0e32dfc-637e-47b2-bf4e-e9b2e58c9da7
            model_name:
              type: string
              example: necolinehubner/Qwen2.5-72B-Instruct
            model_source:
              type: string
              example: huggingface
        message:
          type: string
          example: Processing model weights. Job created.
    MultipartAbortRequest:
      required:
        - upload_id
        - file_id
      type: object
      properties:
        file_id:
          type: string
          description: File ID from initiate response
          example: file-def456
        upload_id:
          type: string
          description: Upload session ID from initiate response
          example: upload-abc123
    MultipartCompleteRequest:
      required:
        - upload_id
        - file_id
        - parts
      type: object
      properties:
        file_id:
          type: string
          description: File ID from initiate response
          example: file-def456
        parts:
          type: array
          items:
            required:
              - PartNumber
              - ETag
            type: object
            properties:
              ETag:
                type: string
                description: ETag returned from S3 part upload
                example: '"abc123def456"'
              PartNumber:
                type: integer
                description: Part number (1-based)
                example: 1
          description: ETags for each successfully uploaded part
        upload_id:
          type: string
          description: Upload session ID from initiate response
          example: upload-abc123
    MultipartInitiateRequest:
      required:
        - filename
        - file_size
        - num_parts
        - purpose
        - file_type
      type: object
      properties:
        file_size:
          type: integer
          description: Total size of the file in bytes
          format: int64
          example: 7516192768
        file_type:
          $ref: '#/components/schemas/FileType'
        filename:
          type: string
          description: The name of the file being uploaded
          example: large_dataset.jsonl
        num_parts:
          maximum: 250
          minimum: 1
          type: integer
          description: Number of parts to split the file into (1-250)
          example: 75
        purpose:
          $ref: '#/components/schemas/FilePurpose'
    MultipartInitiateResponse:
      required:
        - upload_id
        - file_id
        - parts
      type: object
      properties:
        file_id:
          type: string
          description: File ID for the upload
          example: file-def456
        parts:
          type: array
          items:
            $ref: '#/components/schemas/PartInfo'
          description: Presigned URLs and headers for each part
        upload_id:
          type: string
          description: Unique identifier for this multipart upload session
          example: upload-abc123
    PartInfo:
      required:
        - PartNumber
        - URL
      type: object
      properties:
        Headers:
          type: object
          additionalProperties:
            type: string
          description: Headers to include with the upload request
          example:
            Authorization: Bearer token
        PartNumber:
          type: integer
          description: Part number (1-based)
          example: 1
        URL:
          type: string
          description: Presigned URL for uploading this part
          example: https://s3.amazonaws.com/...
    Pricing:
      required:
        - hourly
        - input
        - output
        - base
        - finetune
      type: object
      properties:
        base:
          type: number
          example: 0
        finetune:
          type: number
          example: 0
        hourly:
          type: number
          example: 0
        input:
          type: number
          example: 0.3
        output:
          type: number
          example: 0.3
    PromptPart:
      type: array
      items:
        type: object
        properties:
          logprobs:
            $ref: '#/components/schemas/LogprobsPart'
          text:
            type: string
            example: '<s>[INST] What is the capital of France? [/INST]'
    RerankRequest:
      required:
        - model
        - query
        - documents
      type: object
      properties:
        documents:
          oneOf:
            - type: array
              items:
                type: object
            - type: array
              items:
                type: string
                example: 'Our solar system orbits the Milky Way galaxy at about 515,000 mph'
          description: 'List of documents, which can be either strings or objects.'
          example:
            text: 'The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era.'
            title: Llama
        model:
          type: string
          anyOf:
            - enum:
                - Salesforce/Llama-Rank-v1
              type: string
            - type: string
          description: "The model to be used for the rerank request.<br> <br> [See all of Together AI's rerank models](https://docs.together.ai/docs/serverless-models#rerank-models)\n"
          example: Salesforce/Llama-Rank-V1
        query:
          type: string
          description: The search query to be used for ranking.
          example: What animals can I find near Peru?
        rank_fields:
          type: array
          items:
            type: string
          description: List of keys in the JSON Object document to rank by. Defaults to use all supplied keys for ranking.
          example:
            - title
            - text
        return_documents:
          type: boolean
          description: Whether to return supplied documents with the response.
          example: true
        top_n:
          type: integer
          description: The number of top results to return.
          example: 2
      additionalProperties: false
    RerankResponse:
      required:
        - object
        - model
        - results
      type: object
      properties:
        id:
          type: string
          description: Request ID
          example: 9dfa1a09-5ebc-4a40-970f-586cb8f4ae47
        model:
          type: string
          description: The model to be used for the rerank request.
          example: salesforce/turboranker-0.8-3778-6328
        object:
          enum:
            - rerank
          type: string
          description: Object type
          example: rerank
        results:
          type: array
          items:
            required:
              - index
              - relevance_score
              - document
            type: object
            properties:
              document:
                type: object
                properties:
                  text:
                    type: string
                    nullable: true
              index:
                type: integer
              relevance_score:
                type: number
          example:
            - document:
                text: '{"title":"Llama","text":"The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era."}'
              index: 0
              relevance_score: 0.29980177813003117
            - document:
                text: '{"title":"Guanaco","text":"The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations."}'
              index: 2
              relevance_score: 0.2752447527354349
        usage:
          $ref: '#/components/schemas/UsageData'
    Response:
      title: Response
      type: object
      properties:
        errors:
          type: array
          items:
            title: Error
            oneOf:
              - type: string
              - type: object
    SessionListResponse:
      title: SessionListResponse
      type: object
      allOf:
        - title: Response
          type: object
          properties:
            errors:
              type: array
              items:
                title: Error
                oneOf:
                  - type: string
                  - type: object
        - type: object
          properties:
            data:
              required:
                - sessions
              properties:
                sessions:
                  type: array
                  items:
                    required:
                      - execute_count
                      - expires_at
                      - id
                      - last_execute_at
                      - started_at
                    type: object
                    properties:
                      execute_count:
                        type: integer
                      expires_at:
                        type: string
                        format: date-time
                      id:
                        type: string
                        description: Session Identifier. Used to make follow-up calls.
                        example: ses_abcDEF123
                      last_execute_at:
                        type: string
                        format: date-time
                      started_at:
                        type: string
                        format: date-time
    StreamOutput:
      title: StreamOutput
      required:
        - type
        - data
      properties:
        data:
          type: string
        type:
          enum:
            - stdout
            - stderr
          type: string
      description: Outputs that were printed to stdout or stderr
    StreamSentinel:
      required:
        - data
      type: object
      properties:
        data:
          title: stream_signal
          enum:
            - '[DONE]'
          type: string
    ToolChoice:
      required:
        - id
        - type
        - function
        - index
      type: object
      properties:
        function:
          required:
            - name
            - arguments
          type: object
          properties:
            arguments:
              type: string
            name:
              type: string
              example: function_name
        id:
          type: string
        index:
          type: number
        type:
          enum:
            - function
          type: string
    ToolsPart:
      type: object
      properties:
        function:
          type: object
          properties:
            description:
              type: string
              example: A description of the function.
            name:
              type: string
              example: function_name
            parameters:
              type: object
              description: A map of parameter names to their values.
        type:
          type: string
          example: tool_type
    TrainingMethodDPO:
      required:
        - method
      type: object
      properties:
        dpo_beta:
          type: number
          format: float
          default: 0.1
        dpo_normalize_logratios_by_length:
          type: boolean
          default: false
        dpo_reference_free:
          type: boolean
          default: false
        method:
          enum:
            - dpo
          type: string
        rpo_alpha:
          type: number
          format: float
          default: 0
        simpo_gamma:
          type: number
          format: float
          default: 0
    TrainingMethodSFT:
      required:
        - method
        - train_on_inputs
      type: object
      properties:
        method:
          enum:
            - sft
          type: string
        train_on_inputs:
          type: boolean
          oneOf:
            - type: boolean
            - enum:
                - auto
              type: string
          description: Whether to mask the user messages in conversational data or prompts in instruction data.
          default: auto
    UsageData:
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
        prompt_tokens:
          type: integer
        total_tokens:
          type: integer
      nullable: true
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
      x-bearer-format: bearer
      x-default: default
security:
  - bearerAuth: [ ]